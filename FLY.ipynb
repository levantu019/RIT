{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/levantu019/RIT/blob/main/FLY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive for data storage and model saving\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"✅ Google Drive mounted!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEo-b-BkjrLR",
        "outputId": "002acb08-c0b3-436a-dcdc-37dc701cd656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Google Drive mounted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Block 1: Environment Setup and Installation\n",
        "Purpose: Install required packages and import necessary libraries for YOLOv11 plane detection\n",
        "\"\"\"\n",
        "\n",
        "# Install required packages for YOLOv11 and geospatial processing\n",
        "print(\"Installing required packages...\")\n",
        "!pip install ultralytics roboflow pillow opencv-python matplotlib\n",
        "!pip install rasterio geopandas pyproj shapely\n",
        "\n",
        "# Import standard libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import shutil\n",
        "import yaml\n",
        "from PIL import Image\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Import YOLOv11 from ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Import geospatial libraries for coordinate processing\n",
        "import rasterio\n",
        "from rasterio.transform import xy\n",
        "from rasterio.windows import Window\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "\n",
        "\n",
        "print(\"✅ All packages installed and libraries imported successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESE9Bs3l2swd",
        "outputId": "ab647e38-b199-4307-8397-76c102ba95a7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.189-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.7-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.16-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.8.3)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.189-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roboflow-1.2.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.16-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, ultralytics-thop, roboflow, ultralytics\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.0 pillow-avif-plugin-1.5.2 roboflow-1.2.7 ultralytics-8.3.189 ultralytics-thop-2.0.16\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.12/dist-packages (3.7.2)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (2.1.1)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.8.3)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.2.1)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.3)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas) (25.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.17.0)\n",
            "Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 rasterio-1.4.3\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "✅ All packages installed and libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base directory in Google Drive\n",
        "HOME = '/content/drive/MyDrive/Detection'\n",
        "PATTERNS = f'{HOME}/original_images'\n",
        "COLAB_RUN = f'{HOME}/ColabRun_1'"
      ],
      "metadata": {
        "id": "LYKgEpJLkHjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Block 2: Dataset Preparation and Directory Structure\n",
        "Purpose: Create proper directory structure and prepare .tif images for YOLO training\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def create_dataset_structure():\n",
        "    \"\"\"\n",
        "    Create the required directory structure for YOLO training\n",
        "    \"\"\"\n",
        "    directories = [\n",
        "        f'{COLAB_RUN}/dataset/images/train',\n",
        "        f'{COLAB_RUN}/dataset/images/val',\n",
        "        f'{COLAB_RUN}/dataset/labels/train',\n",
        "        f'{COLAB_RUN}/dataset/labels/val',\n",
        "        f'{PATTERNS}',\n",
        "        f'{COLAB_RUN}/converted_images',\n",
        "        f'{COLAB_RUN}/results'\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "        print(f\"Created directory: {directory}\")\n",
        "\n",
        "    print(\"✅ Dataset structure created successfully!\")\n",
        "\n",
        "def upload_tif_images():\n",
        "    \"\"\"\n",
        "    Instructions for uploading .tif plane pattern images\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"UPLOAD YOUR .TIF PLANE PATTERN IMAGES\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"1. Upload your 150 .tif plane pattern images to: {HOME}/original_images/\")\n",
        "    print(\"2. You can use the file browser on the left side of Colab\")\n",
        "    print(\"3. Or use the following code to upload programmatically:\")\n",
        "    print(\"\")\n",
        "    print(\"from google.colab import files\")\n",
        "    print(\"uploaded = files.upload()\")\n",
        "    print(\"\")\n",
        "    print(\"4. Make sure each .tif file contains one plane pattern\")\n",
        "    print(\"5. Images can be different sizes - they will be automatically resized\")\n",
        "\n",
        "# Create dataset structure\n",
        "create_dataset_structure()\n",
        "\n",
        "# Display upload instructions\n",
        "upload_tif_images()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP8wfQBk2uX_",
        "outputId": "97dfdf49-d50f-4498-f73a-c354e2c44d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory: /content/drive/MyDrive/Detection/ColabRun_1/dataset/images/train\n",
            "Created directory: /content/drive/MyDrive/Detection/ColabRun_1/dataset/images/val\n",
            "Created directory: /content/drive/MyDrive/Detection/ColabRun_1/dataset/labels/train\n",
            "Created directory: /content/drive/MyDrive/Detection/ColabRun_1/dataset/labels/val\n",
            "Created directory: /content/drive/MyDrive/Detection/original_images\n",
            "Created directory: /content/drive/MyDrive/Detection/ColabRun_1/converted_images\n",
            "Created directory: /content/drive/MyDrive/Detection/ColabRun_1/results\n",
            "✅ Dataset structure created successfully!\n",
            "============================================================\n",
            "UPLOAD YOUR .TIF PLANE PATTERN IMAGES\n",
            "============================================================\n",
            "1. Upload your 150 .tif plane pattern images to: /content/drive/MyDrive/Detection/original_images/\n",
            "2. You can use the file browser on the left side of Colab\n",
            "3. Or use the following code to upload programmatically:\n",
            "\n",
            "from google.colab import files\n",
            "uploaded = files.upload()\n",
            "\n",
            "4. Make sure each .tif file contains one plane pattern\n",
            "5. Images can be different sizes - they will be automatically resized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Block 3: Image Conversion and Preprocessing\n",
        "Purpose: Convert .tif images to .jpg format and resize them for YOLO training\n",
        "\"\"\"\n",
        "\n",
        "def convert_tif_to_jpg(input_dir, output_dir, target_size=640):\n",
        "    \"\"\"\n",
        "    Convert .tif images to .jpg format and resize for YOLO training\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Directory containing .tif images\n",
        "        output_dir (str): Directory to save converted .jpg images\n",
        "        target_size (int): Target image size (images will be resized maintaining aspect ratio)\n",
        "\n",
        "    Returns:\n",
        "        list: List of successfully converted filenames\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Check if input directory exists\n",
        "    if not os.path.exists(input_dir):\n",
        "        print(f\"❌ Input directory not found: {input_dir}\")\n",
        "        print(\"Please upload your .tif images first!\")\n",
        "        return []\n",
        "\n",
        "    # Get list of .tif files\n",
        "    tif_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.tif', '.tiff'))]\n",
        "\n",
        "    if len(tif_files) == 0:\n",
        "        print(f\"❌ No .tif files found in {input_dir}\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Found {len(tif_files)} .tif files to convert...\")\n",
        "    converted_files = []\n",
        "\n",
        "    for i, filename in enumerate(tif_files):\n",
        "        print(f\"Processing {i+1}/{len(tif_files)}: {filename}\")\n",
        "\n",
        "        # Full path to input image\n",
        "        img_path = os.path.join(input_dir, filename)\n",
        "\n",
        "        try:\n",
        "            # Read .tif image using OpenCV\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "            if img is None:\n",
        "                print(f\"⚠️  Warning: Could not read {filename}\")\n",
        "                continue\n",
        "\n",
        "            # Get original dimensions\n",
        "            original_height, original_width = img.shape[:2]\n",
        "            print(f\"   Original size: {original_width}x{original_height}\")\n",
        "\n",
        "            # Calculate new dimensions while maintaining aspect ratio\n",
        "            if max(original_height, original_width) > target_size:\n",
        "                if original_height > original_width:\n",
        "                    # Height is larger - resize based on height\n",
        "                    new_height = target_size\n",
        "                    new_width = int(original_width * target_size / original_height)\n",
        "                else:\n",
        "                    # Width is larger - resize based on width\n",
        "                    new_width = target_size\n",
        "                    new_height = int(original_height * target_size / original_width)\n",
        "\n",
        "                # Resize image using high-quality interpolation\n",
        "                img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
        "                print(f\"   Resized to: {new_width}x{new_height}\")\n",
        "            else:\n",
        "                new_width, new_height = original_width, original_height\n",
        "                print(f\"   No resizing needed\")\n",
        "\n",
        "            # Generate output filename (replace .tif with .jpg)\n",
        "            output_filename = filename.replace('.tif', '.jpg').replace('.tiff', '.jpg')\n",
        "            output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "            # Save as high-quality .jpg\n",
        "            success = cv2.imwrite(output_path, img, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
        "\n",
        "            if success:\n",
        "                converted_files.append(output_filename)\n",
        "                print(f\"   ✅ Converted: {filename} -> {output_filename}\")\n",
        "            else:\n",
        "                print(f\"   ❌ Failed to save: {output_filename}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error processing {filename}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"\\n✅ Conversion complete! {len(converted_files)}/{len(tif_files)} files converted successfully.\")\n",
        "    return converted_files\n",
        "\n",
        "# Convert .tif images to .jpg\n",
        "print(\"=\"*60)\n",
        "print(\"CONVERTING .TIF IMAGES TO .JPG FORMAT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "converted_files = convert_tif_to_jpg(f'{HOME}/original_images', f'{COLAB_RUN}/converted_images')\n",
        "\n",
        "if len(converted_files) == 0:\n",
        "    print(\"❌ No files were converted. Please check your .tif images and try again.\")\n",
        "else:\n",
        "    print(f\"✅ Ready for training with {len(converted_files)} plane images!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je2TSxFD2xVV",
        "outputId": "c9d3f4e9-dae3-41d0-d196-687c01d5304f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "CONVERTING .TIF IMAGES TO .JPG FORMAT\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Block 4: Annotation Creation\n",
        "Purpose: Create YOLO format annotations for plane detection\n",
        "Since each image contains one plane pattern, we'll create full-image annotations\n",
        "\"\"\"\n",
        "\n",
        "def create_yolo_annotations(image_dir, label_dir, padding_ratio=0.05):\n",
        "    \"\"\"\n",
        "    Create YOLO format annotations for plane images\n",
        "\n",
        "    Args:\n",
        "        image_dir (str): Directory containing images\n",
        "        label_dir (str): Directory to save label files\n",
        "        padding_ratio (float): Padding around the plane (0.05 = 5% padding)\n",
        "    \"\"\"\n",
        "    # Get list of image files\n",
        "    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')]\n",
        "\n",
        "    if len(image_files) == 0:\n",
        "        print(f\"❌ No .jpg files found in {image_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Creating annotations for {len(image_files)} images...\")\n",
        "\n",
        "    for i, img_file in enumerate(image_files):\n",
        "        # Load image to get dimensions\n",
        "        img_path = os.path.join(image_dir, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"⚠️  Could not read {img_file}\")\n",
        "            continue\n",
        "\n",
        "        height, width = img.shape[:2]\n",
        "\n",
        "        # Create corresponding label file name\n",
        "        label_file = img_file.replace('.jpg', '.txt')\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "        # YOLO format: class_id center_x center_y width height (all normalized 0-1)\n",
        "        # Since each image contains one plane, we'll create a bounding box that covers most of the image\n",
        "\n",
        "        # Calculate bounding box with padding\n",
        "        box_width = 1.0 - (2 * padding_ratio)  # Leave some padding\n",
        "        box_height = 1.0 - (2 * padding_ratio)\n",
        "        center_x = 0.5  # Center of image\n",
        "        center_y = 0.5  # Center of image\n",
        "\n",
        "        # Write annotation file\n",
        "        with open(label_path, 'w') as f:\n",
        "            # Class 0 = plane, followed by normalized coordinates\n",
        "            f.write(f\"0 {center_x} {center_y} {box_width} {box_height}\\n\")\n",
        "\n",
        "        print(f\"   {i+1}/{len(image_files)}: Created annotation for {img_file}\")\n",
        "\n",
        "    print(f\"✅ Created {len(image_files)} annotation files\")\n",
        "\n",
        "def visualize_annotations(dataset_path, num_samples=4):\n",
        "    \"\"\"\n",
        "    Visualize sample images with their annotations to verify correctness\n",
        "\n",
        "    Args:\n",
        "        dataset_path (str): Path to dataset directory\n",
        "        num_samples (int): Number of samples to display\n",
        "    \"\"\"\n",
        "    train_img_dir = os.path.join(dataset_path, 'images/train')\n",
        "    train_label_dir = os.path.join(dataset_path, 'labels/train')\n",
        "\n",
        "    # Get sample image files\n",
        "    img_files = [f for f in os.listdir(train_img_dir) if f.endswith('.jpg')][:num_samples]\n",
        "\n",
        "    if len(img_files) == 0:\n",
        "        print(\"❌ No images found for visualization\")\n",
        "        return\n",
        "\n",
        "    # Create subplot grid\n",
        "    cols = 2\n",
        "    rows = (num_samples + 1) // 2\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
        "\n",
        "    if num_samples == 1:\n",
        "        axes = [axes]\n",
        "    elif rows == 1:\n",
        "        axes = [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "\n",
        "    for i, img_file in enumerate(img_files):\n",
        "        if i >= num_samples:\n",
        "            break\n",
        "\n",
        "        # Load image\n",
        "        img_path = os.path.join(train_img_dir, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n",
        "\n",
        "        # Load corresponding label\n",
        "        label_file = img_file.replace('.jpg', '.txt')\n",
        "        label_path = os.path.join(train_label_dir, label_file)\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            height, width = img.shape[:2]\n",
        "\n",
        "            # Draw bounding boxes\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    class_id, center_x, center_y, box_width, box_height = map(float, parts)\n",
        "\n",
        "                    # Convert normalized coordinates to pixel coordinates\n",
        "                    x_center_pixel = int(center_x * width)\n",
        "                    y_center_pixel = int(center_y * height)\n",
        "                    box_width_pixel = int(box_width * width)\n",
        "                    box_height_pixel = int(box_height * height)\n",
        "\n",
        "                    # Calculate corner coordinates\n",
        "                    x1 = int(x_center_pixel - box_width_pixel/2)\n",
        "                    y1 = int(y_center_pixel - box_height_pixel/2)\n",
        "                    x2 = int(x_center_pixel + box_width_pixel/2)\n",
        "                    y2 = int(y_center_pixel + box_height_pixel/2)\n",
        "\n",
        "                    # Draw bounding box\n",
        "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
        "                    cv2.putText(img, 'PLANE', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "\n",
        "                    # Draw center point\n",
        "                    cv2.circle(img, (x_center_pixel, y_center_pixel), 5, (0, 255, 0), -1)\n",
        "\n",
        "        # Display image\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f'Sample {i+1}: {img_file}', fontsize=10)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    # Hide unused subplots\n",
        "    for i in range(len(img_files), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"✅ Annotation visualization complete!\")\n",
        "\n",
        "# This block will be used after data splitting\n",
        "print(\"✅ Annotation creation functions ready!\")\n",
        "print(\"   Annotations will be created after data splitting in the next block.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-2z1Hx62z4-",
        "outputId": "be82a454-d649-4876-a32b-954017661003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Annotation creation functions ready!\n",
            "   Annotations will be created after data splitting in the next block.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Block 5: Dataset Splitting\n",
        "Purpose: Split the converted images into training and validation sets\n",
        "\"\"\"\n",
        "\n",
        "def split_and_organize_dataset(source_dir, train_ratio=0.8, random_seed=42):\n",
        "    \"\"\"\n",
        "    Split images into train/val sets and organize them in YOLO format\n",
        "\n",
        "    Args:\n",
        "        source_dir (str): Directory containing converted .jpg images\n",
        "        train_ratio (float): Ratio of images for training (0.8 = 80%)\n",
        "        random_seed (int): Random seed for reproducible splits\n",
        "    \"\"\"\n",
        "    # Set random seed for reproducible results\n",
        "    random.seed(random_seed)\n",
        "\n",
        "    # Check if source directory exists\n",
        "    if not os.path.exists(source_dir):\n",
        "        print(f\"❌ Source directory not found: {source_dir}\")\n",
        "        return [], []\n",
        "\n",
        "    # Get all .jpg files\n",
        "    image_files = [f for f in os.listdir(source_dir) if f.lower().endswith('.jpg')]\n",
        "\n",
        "    if len(image_files) == 0:\n",
        "        print(\"❌ No .jpg files found in source directory\")\n",
        "        return [], []\n",
        "\n",
        "    print(f\"Found {len(image_files)} images for dataset splitting\")\n",
        "\n",
        "    # Shuffle images randomly\n",
        "    random.shuffle(image_files)\n",
        "\n",
        "    # Calculate split\n",
        "    train_count = int(len(image_files) * train_ratio)\n",
        "    train_files = image_files[:train_count]\n",
        "    val_files = image_files[train_count:]\n",
        "\n",
        "    # Ensure we have at least 1 validation image\n",
        "    if len(val_files) == 0 and len(train_files) > 1:\n",
        "        val_files = [train_files.pop()]\n",
        "        print(\"⚠️  Moved one image to validation set to ensure validation data exists\")\n",
        "\n",
        "    print(f\"Dataset split:\")\n",
        "    print(f\"   Training images: {len(train_files)} ({len(train_files)/len(image_files)*100:.1f}%)\")\n",
        "    print(f\"   Validation images: {len(val_files)} ({len(val_files)/len(image_files)*100:.1f}%)\")\n",
        "\n",
        "    # Copy images to respective directories\n",
        "    print(\"\\nCopying training images...\")\n",
        "    for i, img_file in enumerate(train_files):\n",
        "        src_path = os.path.join(source_dir, img_file)\n",
        "        dst_path = f'{COLAB_RUN}/dataset/images/train/{img_file}'\n",
        "        try:\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "            if (i + 1) % 20 == 0 or (i + 1) == len(train_files):\n",
        "                print(f\"   Copied {i + 1}/{len(train_files)} training images\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error copying {img_file} to train: {e}\")\n",
        "\n",
        "    print(\"\\nCopying validation images...\")\n",
        "    for i, img_file in enumerate(val_files):\n",
        "        src_path = os.path.join(source_dir, img_file)\n",
        "        dst_path = f'{COLAB_RUN}/dataset/images/val/{img_file}'\n",
        "        try:\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "            print(f\"   Copied {i + 1}/{len(val_files)} validation images\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error copying {img_file} to val: {e}\")\n",
        "\n",
        "    print(\"✅ Dataset splitting and organization complete!\")\n",
        "    return train_files, val_files\n",
        "\n",
        "# Perform dataset splitting\n",
        "print(\"=\"*60)\n",
        "print(\"SPLITTING DATASET INTO TRAIN/VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_files, val_files = split_and_organize_dataset(f'{COLAB_RUN}/converted_images', train_ratio=0.8)\n",
        "\n",
        "if len(train_files) > 0:\n",
        "    # Create annotations for both training and validation sets\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CREATING YOLO ANNOTATIONS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"Creating training annotations...\")\n",
        "    create_yolo_annotations(f'{COLAB_RUN}/dataset/images/train', f'{COLAB_RUN}/dataset/labels/train')\n",
        "\n",
        "    print(\"\\nCreating validation annotations...\")\n",
        "    create_yolo_annotations(f'{COLAB_RUN}/dataset/images/val', f'{COLAB_RUN}/dataset/labels/val')\n",
        "\n",
        "    # Visualize some training samples\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"VISUALIZING TRAINING SAMPLES\")\n",
        "    print(\"=\"*60)\n",
        "    visualize_annotations(f'{COLAB_RUN}/dataset', num_samples=4)\n",
        "\n",
        "else:\n",
        "    print(\"❌ No training files available. Please check the previous steps.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a7eJESpf23Cy",
        "outputId": "97289b88-56c5-4fde-9e01-90df11ce8ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SPLITTING DATASET INTO TRAIN/VALIDATION\n",
            "============================================================\n",
            "Found 153 images for dataset splitting\n",
            "Dataset split:\n",
            "   Training images: 122 (79.7%)\n",
            "   Validation images: 31 (20.3%)\n",
            "\n",
            "Copying training images...\n",
            "   Copied 20/122 training images\n",
            "   Copied 40/122 training images\n",
            "   Copied 60/122 training images\n",
            "   Copied 80/122 training images\n",
            "   Copied 100/122 training images\n",
            "   Copied 120/122 training images\n",
            "   Copied 122/122 training images\n",
            "\n",
            "Copying validation images...\n",
            "   Copied 1/31 validation images\n",
            "   Copied 2/31 validation images\n",
            "   Copied 3/31 validation images\n",
            "   Copied 4/31 validation images\n",
            "   Copied 5/31 validation images\n",
            "   Copied 6/31 validation images\n",
            "   Copied 7/31 validation images\n",
            "   Copied 8/31 validation images\n",
            "   Copied 9/31 validation images\n",
            "   Copied 10/31 validation images\n",
            "   Copied 11/31 validation images\n",
            "   Copied 12/31 validation images\n",
            "   Copied 13/31 validation images\n",
            "   Copied 14/31 validation images\n",
            "   Copied 15/31 validation images\n",
            "   Copied 16/31 validation images\n",
            "   Copied 17/31 validation images\n",
            "   Copied 18/31 validation images\n",
            "   Copied 19/31 validation images\n",
            "   Copied 20/31 validation images\n",
            "   Copied 21/31 validation images\n",
            "   Copied 22/31 validation images\n",
            "   Copied 23/31 validation images\n",
            "   Copied 24/31 validation images\n",
            "   Copied 25/31 validation images\n",
            "   Copied 26/31 validation images\n",
            "   Copied 27/31 validation images\n",
            "   Copied 28/31 validation images\n",
            "   Copied 29/31 validation images\n",
            "   Copied 30/31 validation images\n",
            "   Copied 31/31 validation images\n",
            "✅ Dataset splitting and organization complete!\n",
            "\n",
            "============================================================\n",
            "CREATING YOLO ANNOTATIONS\n",
            "============================================================\n",
            "Creating training annotations...\n",
            "Creating annotations for 122 images...\n",
            "   1/122: Created annotation for TQS_0.702650249004364_0_PSScene_20250722_032938_72_24d3_cloud_0_12.25265627298675_112.84121294422535.jpg\n",
            "   2/122: Created annotation for TQS_0.5561262965202332_0_PSScene_20250717_025241_04_250d_cloud_22.0_37.646619891713826_123.43520128959801.jpg\n",
            "   3/122: Created annotation for TQS_0.7226024866104126_0_PSScene_20250729_025330_44_251a_cloud_0_11.819497419280557_119.61831224081618.jpg\n",
            "   4/122: Created annotation for TQS_0.7284969687461853_0_PSScene_20250622_031934_17_2507_cloud_7.000000000000001_13.572014141039446_112.73986674978049.jpg\n",
            "   5/122: Created annotation for TQS_0.8191806674003601_0_PSScene_20250629_034320_41_251d_cloud_1.0_6.57871400431167_105.39766488410578.jpg\n",
            "   6/122: Created annotation for TQS_0.7425211071968079_17_PSScene_20250625_032047_01_24d1_cloud_10.0_22.17242087018277_114.08622884243825.jpg\n",
            "   7/122: Created annotation for TQS_0.6295386552810669_2_PSScene_20250716_025723_23_24f7_cloud_1.0_24.63379620081544_120.43829679361049.jpg\n",
            "   8/122: Created annotation for TQS_0.5876418352127075_3_PSScene_20250723_074619_54_2506_cloud_0_29.289751924202264_48.94210165882199.jpg\n",
            "   9/122: Created annotation for TQS_0.6154696345329285_0_PSScene_20250710_033410_40_24ae_cloud_0_10.720339422867244_109.27904856614911.jpg\n",
            "   10/122: Created annotation for TQS_0.6666328310966492_0_PSScene_20250630_034730_84_253f_cloud_0_4.165024756994904_106.38248009131229.jpg\n",
            "   11/122: Created annotation for TQS_0.6487221717834473_0_PSScene_20250730_033300_84_24f6_cloud_0_14.10705388987327_111.59519583542757.jpg\n",
            "   12/122: Created annotation for TQS_0.5188239812850952_0_PSScene_20250615_083112_77_251e_cloud_0_22.807460179919847_38.19218167402983.jpg\n",
            "   13/122: Created annotation for TQS_0.7637919187545776_2_PSScene_20250717_025238_81_250d_cloud_43.0_37.649880699506284_123.43605126979963.jpg\n",
            "   14/122: Created annotation for TQS_0.5845882892608643_2_PSScene_20250714_033556_73_2546_cloud_2.0_15.225380650344_110.82037491988045.jpg\n",
            "   15/122: Created annotation for TQS_0.634296715259552_5_PSScene_20250709_073244_85_24dc_cloud_1.0_26.568048118961972_51.728959009677325.jpg\n",
            "   16/122: Created annotation for TQS_0.5489500164985657_0_PSScene_20250101_025916_34_24d3_cloud_3.0_10.582754751437184_115.89333749449163.jpg\n",
            "   17/122: Created annotation for TQS_0.6219092011451721_24_PSScene_20250721_075554_68_24f4_cloud_0_29.04878065915166_48.367827195271936.jpg\n",
            "   18/122: Created annotation for TQS_0.6018040776252747_4_PSScene_20250622_072753_97_2535_cloud_0_25.34001602638871_54.46387650109715.jpg\n",
            "   19/122: Created annotation for TQS_0.7228941321372986_0_PSScene_20250701_033957_44_24f6_cloud_0_10.246294098449193_108.86495216611294.jpg\n",
            "   20/122: Created annotation for TQS_0.8147010207176208_1_PSScene_20250619_033424_08_2508_cloud_12.0_10.699513130044918_109.34064460046532.jpg\n",
            "   21/122: Created annotation for TQS_0.6507008075714111_0_PSScene_20250708_033956_10_24dd_cloud_4.0_8.443484109440027_109.08785627698437.jpg\n",
            "   22/122: Created annotation for TQS_0.6181579828262329_1_PSScene_20250608_025236_70_24bd_cloud_9.0_18.53273427832191_120.5549618890423.jpg\n",
            "   23/122: Created annotation for TQS_0.6892819404602051_2_PSScene_20250716_025718_78_24f7_cloud_0_24.84269358489992_120.63859518316814.jpg\n",
            "   24/122: Created annotation for TQS_0.5364556908607483_3_PSScene_20250626_025223_92_251f_cloud_20.0_25.52188622578201_121.66462654818095.jpg\n",
            "   25/122: Created annotation for TQS_0.6069465279579163_4_PSScene_20250701_074457_83_2535_cloud_0_27.085469082984417_50.66846356281344.jpg\n",
            "   26/122: Created annotation for TQS_0.5275038480758667_2_PSScene_20250621_082949_32_24aa_cloud_0_21.37594916749285_38.90198617455236.jpg\n",
            "   27/122: Created annotation for TQS_0.5343968272209167_2_PSScene_20250714_023643_42_2515_cloud_57.99999999999999_33.5248617895091_126.516284538713.jpg\n",
            "   28/122: Created annotation for TQS_0.6621910929679871_0_PSScene_20250723_074623_58_2506_cloud_0_29.104819833206125_48.94082538380943.jpg\n",
            "   29/122: Created annotation for TQS_0.5387697219848633_0_PSScene_20250628_025930_79_250f_cloud_25.0_20.456074643472046_120.71612083121627.jpg\n",
            "   30/122: Created annotation for TQS_0.6685602068901062_0_PSScene_20250713_064204_51_251a_cloud_40.0_24.134184153382996_63.88071638855088.jpg\n",
            "   31/122: Created annotation for TQS_0.6908575892448425_5_PSScene_20250629_034554_30_253e_cloud_2.0_6.3602542468703955_107.56963121290573.jpg\n",
            "   32/122: Created annotation for TQS_0.7141587138175964_0_PSScene_20250609_072856_93_2533_cloud_0_13.330848042868658_52.20092929511453.jpg\n",
            "   33/122: Created annotation for TQS_0.7556126713752747_2_PSScene_20250709_072812_67_251e_cloud_0_14.320269301744705_52.859882533797276.jpg\n",
            "   34/122: Created annotation for TQS_0.5784642100334167_2_PSScene_20250625_071701_06_2533_cloud_0_24.96606980709539_57.14379140444971.jpg\n",
            "   35/122: Created annotation for TQS_0.6393203735351562_0_PSScene_20250619_065217_48_24fb_cloud_50.0_24.591870071630208_62.68406388390749.jpg\n",
            "   36/122: Created annotation for TQS_0.5817424058914185_0_PSScene_20250707_034934_78_2538_cloud_12.0_5.754134606435864_106.55066436744885.jpg\n",
            "   37/122: Created annotation for TQS_0.6353746652603149_0_PSScene_20250614_065010_63_2507_cloud_0_24.701087454561474_61.62166078038634.jpg\n",
            "   38/122: Created annotation for TQS_0.783861517906189_0_PSScene_20250723_035342_17_2546_cloud_0_7.178084369106597_105.67384103758218.jpg\n",
            "   39/122: Created annotation for TQS_0.7684765458106995_0_PSScene_20250629_033940_85_2549_cloud_0_14.137279694568608_110.1475641289716.jpg\n",
            "   40/122: Created annotation for TQS_0.7556275129318237_0_PSScene_20250722_035254_90_24f9_cloud_1.0_8.113482517601247_106.24208470386654.jpg\n",
            "   41/122: Created annotation for TQS_0.7520698308944702_0_PSScene_20250716_025721_01_24f7_cloud_0_24.6336606298553_120.43830421604603.jpg\n",
            "   42/122: Created annotation for TQS_0.535279393196106_1_PSScene_20250709_030934_44_253a_cloud_28.999999999999996_16.861105287145097_117.68635316359963.jpg\n",
            "   43/122: Created annotation for TQS_0.5035929083824158_0_PSScene_20250712_030943_36_2547_cloud_1.0_19.883298285127132_118.69764400673698.jpg\n",
            "   44/122: Created annotation for TQS_0.7603864669799805_0_PSScene_20250713_030054_57_2532_cloud_20.0_16.90729583540094_119.78776965808584.jpg\n",
            "   45/122: Created annotation for TQS_0.6120601892471313_1_PSScene_20250707_063619_36_2417_cloud_4.0_24.545920919358444_59.20279058570602.jpg\n",
            "   46/122: Created annotation for TQS_0.5667705535888672_4_PSScene_20250711_033456_58_24dc_cloud_2.0_8.86530567448268_109.39273900716137.jpg\n",
            "   47/122: Created annotation for TQS_0.8435266613960266_0_PSScene_20250709_072815_01_251e_cloud_0_14.317356421341898_52.85933339721995.jpg\n",
            "   48/122: Created annotation for TQS_0.6358151435852051_0_PSScene_20250615_035332_09_254a_cloud_11.0_6.0738904763306305_105.29473491023516.jpg\n",
            "   49/122: Created annotation for TQS_0.7446677684783936_1_PSScene_20250713_064202_49_251a_cloud_43.0_24.134538166713458_63.88167661681919.jpg\n",
            "   50/122: Created annotation for TQS_0.6515558362007141_0_PSScene_20250629_034247_93_2409_cloud_11.0_7.941998464675604_106.13609266345318.jpg\n",
            "   51/122: Created annotation for TQS_0.7026446461677551_5_PSScene_20250625_073221_98_24dc_cloud_0_26.549954368147713_51.79684713457427.jpg\n",
            "   52/122: Created annotation for TQS_0.7633850574493408_0_PSScene_20250617_072717_07_2506_cloud_0_25.66381816361223_53.188630590773506.jpg\n",
            "   53/122: Created annotation for TQS_0.5250651836395264_1_PSScene_20250630_034054_90_24f0_cloud_2.0_9.082036295864416_106.86078696878471.jpg\n",
            "   54/122: Created annotation for TQS_0.5037254691123962_0_PSScene_20250701_033955_30_24f6_cloud_0_10.413113560917424_108.86198079101021.jpg\n",
            "   55/122: Created annotation for TQS_0.562483549118042_2_PSScene_20250628_034033_02_24fb_cloud_9.0_8.195482165488377_108.92865379368415.jpg\n",
            "   56/122: Created annotation for TQS_0.599986732006073_2_PSScene_20250709_084521_71_2516_cloud_0_32.37445377848782_34.41004245095228.jpg\n",
            "   57/122: Created annotation for TQS_0.5880364775657654_1_PSScene_20250710_073409_29_24b8_cloud_0_12.895781851755167_51.23295396217943.jpg\n",
            "   58/122: Created annotation for TQS_0.5585706233978271_0_PSScene_20250722_033228_24_2522_cloud_17.0_12.040503326606311_111.62389803185907.jpg\n",
            "   59/122: Created annotation for TQS_0.5669981837272644_1_PSScene_20250621_023427_94_24df_cloud_8.0_29.407122504902503_128.02327738359676.jpg\n",
            "   60/122: Created annotation for TQS_0.550973117351532_1_PSScene_20250707_063617_53_2417_cloud_4.0_24.547940450760656_59.20362775337995.jpg\n",
            "   61/122: Created annotation for TQS_0.5886442065238953_4_PSScene_20250714_023641_38_2515_cloud_25.0_33.52496257530634_126.51610584975892.jpg\n",
            "   62/122: Created annotation for TQS_0.5505537986755371_0_PSScene_20250629_035433_15_252e_cloud_1.0_6.470675303761509_105.23427806988614.jpg\n",
            "   63/122: Created annotation for TQS_0.5151451826095581_34_PSScene_20250615_082653_05_2541_cloud_0_21.419646695252286_39.124361172551396.jpg\n",
            "   64/122: Created annotation for TQS_0.5888789892196655_2_PSScene_20250625_071414_48_2527_cloud_0_24.79154233665514_57.87737061502936.jpg\n",
            "   65/122: Created annotation for TQS_0.5950449705123901_0_PSScene_20250722_082933_09_24db_cloud_0_23.261752191032606_37.10765831661461.jpg\n",
            "   66/122: Created annotation for TQS_0.5029637813568115_4_PSScene_20250610_031940_08_24db_cloud_0_21.641355102174426_113.5936512271808.jpg\n",
            "   67/122: Created annotation for TQS_0.5034570097923279_0_PSScene_20250708_024946_98_24df_cloud_52.0_30.349515875339673_125.18008377642128.jpg\n",
            "   68/122: Created annotation for TQS_0.5628373622894287_1_PSScene_20250723_032628_36_2511_cloud_0_11.134776344596924_110.97734161106338.jpg\n",
            "   69/122: Created annotation for TQS_0.5431678891181946_28_PSScene_20250622_073130_29_24db_cloud_0_25.989181671511577_51.54014132028693.jpg\n",
            "   70/122: Created annotation for TQS_0.5764045715332031_0_PSScene_20250818_024406_88_2506_cloud_9.0_30.93500875708292_125.34868686074611.jpg\n",
            "   71/122: Created annotation for TQS_0.5039116740226746_1_PSScene_20250704_025850_95_2530_cloud_0_25.449203591550848_121.40022958321002.jpg\n",
            "   72/122: Created annotation for TQS_0.6307888627052307_0_PSScene_20250716_025151_63_24f4_cloud_28.000000000000004_26.75882926405068_124.13812837952169.jpg\n",
            "   73/122: Created annotation for TQS_0.5761414766311646_6_PSScene_20250722_072337_25_24f4_cloud_0_26.353606902787188_56.09003891691099.jpg\n",
            "   74/122: Created annotation for TQS_0.560839056968689_3_PSScene_20250706_071448_42_2526_cloud_0_24.42980390992487_57.538609389108906.jpg\n",
            "   75/122: Created annotation for TQS_0.556998074054718_0_PSScene_20250619_033936_26_253d_cloud_22.0_8.956621221036272_109.45416531815042.jpg\n",
            "   76/122: Created annotation for TQS_0.635858416557312_0_PSScene_20250722_084239_43_2515_cloud_16.0_32.28930427153129_34.68643033063746.jpg\n",
            "   77/122: Created annotation for TQS_0.6742160320281982_1_PSScene_20250616_034113_42_24d3_cloud_1.0_10.465661280833539_109.07492512218757.jpg\n",
            "   78/122: Created annotation for TQS_0.7832962870597839_1_PSScene_20250613_031824_70_24da_cloud_10.0_17.052573387221575_113.70371784538871.jpg\n",
            "   79/122: Created annotation for TQS_0.7142947912216187_0_PSScene_20250620_085125_88_24f2_cloud_0_34.0737129126072_35.256952236837854.jpg\n",
            "   80/122: Created annotation for TQS_0.5695866346359253_2_PSScene_20250723_073320_46_254a_cloud_1.0_26.26320399085439_53.08857961772515.jpg\n",
            "   81/122: Created annotation for TQS_0.5264419317245483_1_PSScene_20250714_030715_01_2538_cloud_3.0_23.18134725754592_119.61736565866589.jpg\n",
            "   82/122: Created annotation for TQS_0.5134993195533752_0_PSScene_20250623_031922_88_24d5_cloud_15.0_15.89498810830412_114.61263235485805.jpg\n",
            "   83/122: Created annotation for TQS_0.6947777271270752_0_PSScene_20250616_030023_74_2535_cloud_0_35.88806636037124_123.38865759695872.jpg\n",
            "   84/122: Created annotation for TQS_0.7452171444892883_0_PSScene_20250710_033012_89_252e_cloud_7.000000000000001_17.122154192414126_112.3761906884984.jpg\n",
            "   85/122: Created annotation for TQS_0.5811580419540405_0_PSScene_20250706_070040_53_251b_cloud_28.000000000000004_24.670353960385498_59.711167773697504.jpg\n",
            "   86/122: Created annotation for TQS_0.5663818120956421_0_PSScene_20250714_025240_79_24e1_cloud_16.0_11.808531264946158_121.65447081396414.jpg\n",
            "   87/122: Created annotation for TQS_0.6200425624847412_0_PSScene_20250716_024721_58_24eb_cloud_9.0_28.40891105788423_124.04734259581681.jpg\n",
            "   88/122: Created annotation for TQS_0.6828830242156982_0_PSScene_20250711_033458_79_24dc_cloud_6.0_8.863090217867486_109.39226945387773.jpg\n",
            "   89/122: Created annotation for TQS_0.5904063582420349_1_PSScene_20250714_072725_39_24fd_cloud_0_14.268794677185683_52.66100238889434.jpg\n",
            "   90/122: Created annotation for TQS_0.5724695324897766_0_PSScene_20250709_023924_23_251d_cloud_6.0_29.92398576720627_125.17078019997122.jpg\n",
            "   91/122: Created annotation for TQS_0.5153062343597412_1_PSScene_20250711_033911_63_2532_cloud_0_13.46320570468919_109.68118743374232.jpg\n",
            "   92/122: Created annotation for TQS_0.7347320914268494_0_PSScene_20250710_033634_01_2531_cloud_0_14.695076041493156_110.54609797080552.jpg\n",
            "   93/122: Created annotation for TQS_0.5757678151130676_4_PSScene_20250619_024741_19_2522_cloud_62.0_37.300643200608654_126.51426361284078.jpg\n",
            "   94/122: Created annotation for TQS_0.6136832237243652_16_PSScene_20250707_032642_60_2527_cloud_0_21.858335166186766_114.13433010606849.jpg\n",
            "   95/122: Created annotation for TQS_0.6711932420730591_0_PSScene_20250713_032714_57_253a_cloud_5.0_19.201013041267696_113.38538625993989.jpg\n",
            "   96/122: Created annotation for TQS_0.7851415276527405_0_PSScene_20250723_024412_40_2516_cloud_25.0_28.199655450140632_123.94061132165753.jpg\n",
            "   97/122: Created annotation for TQS_0.620694637298584_0_PSScene_20250708_023122_38_251f_cloud_2.0_31.204168074959135_127.39203355356136.jpg\n",
            "   98/122: Created annotation for TQS_0.6908041834831238_17_PSScene_20250617_030139_49_24da_cloud_0_38.95349462463723_121.69805943426853.jpg\n",
            "   99/122: Created annotation for TQS_0.5645233392715454_4_PSScene_20250630_031500_46_251d_cloud_22.0_20.8774010367168_114.55187701231392.jpg\n",
            "   100/122: Created annotation for TQS_0.7020443081855774_0_PSScene_20250623_072714_66_2504_cloud_0_25.7881973769972_54.69422504060138.jpg\n",
            "   101/122: Created annotation for TQS_0.5034496188163757_3_PSScene_20250705_024652_95_2538_cloud_10.0_27.465764203895038_125.09628170522936.jpg\n",
            "   102/122: Created annotation for TQS_0.691072404384613_1_PSScene_20250706_072234_99_24dc_cloud_0_14.634246310539645_53.06054179969623.jpg\n",
            "   103/122: Created annotation for TQS_0.6659038662910461_0_PSScene_20250621_023425_79_24df_cloud_2.0_29.405587536415137_128.02418958631776.jpg\n",
            "   104/122: Created annotation for TQS_0.7122786641120911_2_PSScene_20250818_025208_72_2526_cloud_2.0_28.668921473627517_123.67447755556056.jpg\n",
            "   105/122: Created annotation for TQS_0.647339403629303_8_PSScene_20250613_071353_33_2531_cloud_0_24.365536064004726_57.7576919260579.jpg\n",
            "   106/122: Created annotation for TQS_0.5122444033622742_1_PSScene_20250714_070152_10_24c6_cloud_32.0_24.11970505597461_61.28798152771103.jpg\n",
            "   107/122: Created annotation for TQS_0.5192939639091492_0_PSScene_20250615_034247_24_2515_cloud_7.000000000000001_7.451911721936663_105.93778637408394.jpg\n",
            "   108/122: Created annotation for TQS_0.5505262017250061_1_PSScene_20250630_031625_03_2417_cloud_60.0_8.184267631266284_106.80592567798912.jpg\n",
            "   109/122: Created annotation for TQS_0.659913957118988_2_PSScene_20250627_031952_24_24f0_cloud_34.0_21.840249943204714_113.61642528246347.jpg\n",
            "   110/122: Created annotation for TQS_0.6579199433326721_0_PSScene_20250709_034753_74_251f_cloud_0_2.702475150699735_104.45634388408715.jpg\n",
            "   111/122: Created annotation for TQS_0.6888164281845093_1_PSScene_20250610_035106_52_2547_cloud_28.000000000000004_4.9322785674123315_105.90783566639841.jpg\n",
            "   112/122: Created annotation for TQS_0.5843077898025513_1_PSScene_20250711_035129_01_24eb_cloud_2.0_5.486144013840464_104.74303511436537.jpg\n",
            "   113/122: Created annotation for TQS_0.6185100078582764_9_PSScene_20250620_030526_62_24fd_cloud_46.0_38.7821131416887_122.02890836144176.jpg\n",
            "   114/122: Created annotation for TQS_0.5814488530158997_0_PSScene_20250702_025804_41_24fd_cloud_3.0_22.80724794135376_121.32163231107211.jpg\n",
            "   115/122: Created annotation for TQS_0.5104240775108337_5_PSScene_20250623_075340_95_2522_cloud_0_28.872085498967163_48.68224878120927.jpg\n",
            "   116/122: Created annotation for TQS_0.5258960127830505_3_PSScene_20250717_025936_19_2508_cloud_1.0_24.990145705468052_120.80596955261062.jpg\n",
            "   117/122: Created annotation for TQS_0.57938551902771_4_PSScene_20250623_032504_15_24b8_cloud_1.0_21.50281559397011_114.55504266922702.jpg\n",
            "   118/122: Created annotation for TQS_0.5405364036560059_2_PSScene_20250614_033505_13_24d5_cloud_2.0_12.539623688323351_110.51555938993235.jpg\n",
            "   119/122: Created annotation for TQS_0.6215440630912781_0_PSScene_20250624_084757_19_2541_cloud_0_27.69406039302508_34.64409640857555.jpg\n",
            "   120/122: Created annotation for TQS_0.6339827179908752_1_PSScene_20250614_032700_26_24fa_cloud_0_10.919506377275432_110.74888263153031.jpg\n",
            "   121/122: Created annotation for TQS_0.565614640712738_0_PSScene_20250614_073247_94_2533_cloud_8.0_12.145661052675967_51.49026297430525.jpg\n",
            "   122/122: Created annotation for TQS_0.7423539161682129_1_PSScene_20250623_064953_19_2534_cloud_2.0_23.052243636592006_63.77605186958451.jpg\n",
            "✅ Created 122 annotation files\n",
            "\n",
            "Creating validation annotations...\n",
            "Creating annotations for 31 images...\n",
            "   1/31: Created annotation for TQS_0.6274324059486389_1_PSScene_20250709_070616_42_2521_cloud_10.0_24.36531870728903_57.75741241148046.jpg\n",
            "   2/31: Created annotation for TQS_0.6187233328819275_12_PSScene_20250716_025626_08_251d_cloud_0_23.84257265983824_119.8251746383562.jpg\n",
            "   3/31: Created annotation for TQS_0.5859873294830322_1_PSScene_20250619_033758_80_2515_cloud_14.000000000000002_9.422470565488577_107.02620236922938.jpg\n",
            "   4/31: Created annotation for TQS_0.6585144400596619_0_PSScene_20250616_031608_00_24dd_cloud_0_17.033857208312753_115.74751367207438.jpg\n",
            "   5/31: Created annotation for TQS_0.824091911315918_0_PSScene_20250726_034548_07_251e_cloud_31.0_9.548704122107408_107.15412200558664.jpg\n",
            "   6/31: Created annotation for TQS_0.6665493845939636_2_PSScene_20250708_034341_98_24d3_cloud_5.0_7.997207598870618_108.78698130386283.jpg\n",
            "   7/31: Created annotation for TQS_0.7478458881378174_1_PSScene_20250723_075401_74_24f9_cloud_0_28.882323879960293_49.250436290398255.jpg\n",
            "   8/31: Created annotation for TQS_0.8312220573425293_0_PSScene_20250622_032402_83_2521_cloud_6.0_11.31688327191457_111.10691492349497.jpg\n",
            "   9/31: Created annotation for TQS_0.5928162336349487_2_PSScene_20250608_030049_60_2539_cloud_62.0_25.151470573862937_121.1927683368039.jpg\n",
            "   10/31: Created annotation for TQS_0.7131901383399963_1_PSScene_20250701_033834_60_250d_cloud_0_9.825775546304802_107.34275149217403.jpg\n",
            "   11/31: Created annotation for TQS_0.8012580275535583_0_PSScene_20250713_085513_54_2518_cloud_0_34.623841332648304_32.624711911938455.jpg\n",
            "   12/31: Created annotation for TQS_0.6015170216560364_3_PSScene_20250626_030048_00_24f9_cloud_1.0_25.005756035082914_120.9346269452152.jpg\n",
            "   13/31: Created annotation for TQS_0.5380614995956421_0_PSScene_20250711_034845_55_2527_cloud_0_7.592692377054783_107.00634619469763.jpg\n",
            "   14/31: Created annotation for TQS_0.586421549320221_1_PSScene_20250625_024501_13_2417_cloud_31.0_20.222227140873812_115.93009295245085.jpg\n",
            "   15/31: Created annotation for TQS_0.5182004570960999_1_PSScene_20250818_025410_86_24e9_cloud_2.0_28.393241668315678_123.56315996601967.jpg\n",
            "   16/31: Created annotation for TQS_0.534563422203064_0_PSScene_20250717_084732_93_2514_cloud_0_32.669252516741736_33.81590035332513.jpg\n",
            "   17/31: Created annotation for TQS_0.6354729533195496_0_PSScene_20250628_032726_59_24b8_cloud_44.0_14.25904754746678_113.26399427587864.jpg\n",
            "   18/31: Created annotation for TQS_0.7104315757751465_2_PSScene_20250626_032410_44_253f_cloud_6.0_17.087628617181664_113.71720704767458.jpg\n",
            "   19/31: Created annotation for TQS_0.6742299795150757_2_PSScene_20250616_075149_87_2531_cloud_0_28.946200143653584_48.82043323211357.jpg\n",
            "   20/31: Created annotation for TQS_0.6664971709251404_5_PSScene_20250612_025104_61_252e_cloud_1.0_37.5780303141586_126.2137400735219.jpg\n",
            "   21/31: Created annotation for TQS_0.8209347724914551_3_PSScene_20250612_070113_13_2523_cloud_0_24.06189259904822_58.719050815417425.jpg\n",
            "   22/31: Created annotation for TQS_0.5292251706123352_2_PSScene_20250712_032217_43_2523_cloud_23.0_15.070811050963252_112.27780505096752.jpg\n",
            "   23/31: Created annotation for TQS_0.6462001204490662_3_PSScene_20250616_024848_28_2409_cloud_1.0_22.04156540642694_121.20465824601173.jpg\n",
            "   24/31: Created annotation for TQS_0.560535728931427_1_PSScene_20250723_025817_07_2539_cloud_3.0_25.904181500226784_122.08897465041522.jpg\n",
            "   25/31: Created annotation for TQS_0.5860643982887268_3_PSScene_20250618_025547_55_24db_cloud_60.0_37.785198044922886_122.90513323317619.jpg\n",
            "   26/31: Created annotation for TQS_0.5790761709213257_1_PSScene_20250620_085128_02_24f2_cloud_1.0_34.072080047946336_35.256708868590906.jpg\n",
            "   27/31: Created annotation for TQS_0.7593719959259033_5_PSScene_20250627_031954_26_24f0_cloud_16.0_21.840577354284154_113.62019457972586.jpg\n",
            "   28/31: Created annotation for TQS_0.5597674250602722_1_PSScene_20250629_024919_42_24c6_cloud_73.0_33.89126874817043_125.95852122823563.jpg\n",
            "   29/31: Created annotation for TQS_0.7657690644264221_0_PSScene_20250701_033929_06_2512_cloud_12.0_6.347334038784904_106.37553975112463.jpg\n",
            "   30/31: Created annotation for TQS_0.6043542623519897_0_PSScene_20250611_030110_96_2500_cloud_2.0_22.612246381135627_118.49861195860649.jpg\n",
            "   31/31: Created annotation for TQS_0.6893817782402039_0_PSScene_20250619_034646_34_24ed_cloud_0_17.115409084403936_107.65779720317686.jpg\n",
            "✅ Created 31 annotation files\n",
            "\n",
            "============================================================\n",
            "VISUALIZING TRAINING SAMPLES\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Annotation visualization complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Block 6: Dataset Configuration\n",
        "Purpose: Create YOLO dataset configuration file (data.yaml)\n",
        "\"\"\"\n",
        "\n",
        "def create_dataset_config():\n",
        "    \"\"\"\n",
        "    Create YOLO dataset configuration file\n",
        "    \"\"\"\n",
        "    # Dataset configuration for YOLO\n",
        "    data_config = {\n",
        "        'path': f'{COLAB_RUN}/dataset',  # Root directory of dataset\n",
        "        'train': 'images/train',     # Training images directory (relative to path)\n",
        "        'val': 'images/val',         # Validation images directory (relative to path)\n",
        "        'nc': 1,                     # Number of classes\n",
        "        'names': ['plane']           # Class names (class 0 = plane)\n",
        "    }\n",
        "\n",
        "    # Save configuration to YAML file\n",
        "    config_path = f'{COLAB_RUN}/dataset/data.yaml'\n",
        "    with open(config_path, 'w') as f:\n",
        "        yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "    print(\"✅ Dataset configuration created!\")\n",
        "    print(f\"   Config file: {config_path}\")\n",
        "    print(f\"   Classes: {data_config['nc']} (plane)\")\n",
        "    print(f\"   Training path: {data_config['path']}/{data_config['train']}\")\n",
        "    print(f\"   Validation path: {data_config['path']}/{data_config['val']}\")\n",
        "\n",
        "    return config_path\n",
        "\n",
        "def verify_dataset_structure():\n",
        "    \"\"\"\n",
        "    Verify that dataset structure is correct for YOLO training\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"VERIFYING DATASET STRUCTURE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Check required directories\n",
        "    required_dirs = [\n",
        "        f'{COLAB_RUN}/dataset/images/train',\n",
        "        f'{COLAB_RUN}/dataset/images/val', # Corrected path\n",
        "        f'{COLAB_RUN}/dataset/labels/train', # Corrected path\n",
        "        f'{COLAB_RUN}/dataset/labels/val' # Corrected path\n",
        "    ]\n",
        "\n",
        "    for directory in required_dirs:\n",
        "        if os.path.exists(directory):\n",
        "            file_count = len([f for f in os.listdir(directory) if not f.startswith('.')])\n",
        "            print(f\"✅ {directory}: {file_count} files\")\n",
        "        else:\n",
        "            print(f\"❌ Missing: {directory}\")\n",
        "            return False\n",
        "\n",
        "    # Check that data.yaml exists\n",
        "    if os.path.exists(f'{COLAB_RUN}/dataset/data.yaml'):\n",
        "        print(\"✅ Dataset configuration file: data.yaml\")\n",
        "    else:\n",
        "        print(\"❌ Missing: data.yaml\")\n",
        "        return False\n",
        "\n",
        "    # Verify matching image/label pairs\n",
        "    train_images = set([f.replace('.jpg', '') for f in os.listdir(f'{COLAB_RUN}/dataset/images/train') if f.endswith('.jpg')])\n",
        "    train_labels = set([f.replace('.txt', '') for f in os.listdir(f'{COLAB_RUN}/dataset/labels/train') if f.endswith('.txt')])\n",
        "\n",
        "    val_images = set([f.replace('.jpg', '') for f in os.listdir(f'{COLAB_RUN}/dataset/images/val') if f.endswith('.jpg')])\n",
        "    val_labels = set([f.replace('.txt', '') for f in os.listdir(f'{COLAB_RUN}/dataset/labels/val') if f.endswith('.txt')])\n",
        "\n",
        "    if train_images == train_labels:\n",
        "        print(f\"✅ Training set: {len(train_images)} matching image/label pairs\")\n",
        "    else:\n",
        "        print(f\"❌ Training set: Mismatched image/label pairs\")\n",
        "        # return False # Allow verification to continue even with mismatch for clearer output\n",
        "\n",
        "    if val_images == val_labels:\n",
        "        print(f\"✅ Validation set: {len(val_images)} matching image/label pairs\")\n",
        "    else:\n",
        "        print(f\"❌ Validation set: Mismatched image/label pairs\")\n",
        "        # return False # Allow verification to continue even with mismatch for clearer output\n",
        "\n",
        "    print(\"\\n✅ Dataset structure verification complete!\")\n",
        "    print(\"   Dataset is ready for YOLO training!\")\n",
        "    return True # Return True if data.yaml exists and directories are present\n",
        "\n",
        "# Create dataset configuration\n",
        "config_path = create_dataset_config()\n",
        "\n",
        "# Verify dataset structure\n",
        "dataset_ready = verify_dataset_structure()\n",
        "\n",
        "if not dataset_ready:\n",
        "    print(\"\\n❌ Dataset structure issues detected. Please fix before training.\")\n",
        "else:\n",
        "    # Need to re-calculate train_files length as it's not globally available here\n",
        "    try:\n",
        "        train_files_count = len([f for f in os.listdir(f'{COLAB_RUN}/dataset/images/train') if f.endswith('.jpg')])\n",
        "        print(f\"\\n🎯 Dataset ready for training with {train_files_count} training images!\")\n",
        "    except FileNotFoundError:\n",
        "         print(\"\\n🎯 Dataset ready for training but training image directory not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tkrqArr25QL",
        "outputId": "25c01556-b65a-45bb-e3c7-9e7b6446cf9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset configuration created!\n",
            "   Config file: /content/drive/MyDrive/Detection/ColabRun_1/dataset/data.yaml\n",
            "   Classes: 1 (plane)\n",
            "   Training path: /content/drive/MyDrive/Detection/ColabRun_1/dataset/images/train\n",
            "   Validation path: /content/drive/MyDrive/Detection/ColabRun_1/dataset/images/val\n",
            "\n",
            "============================================================\n",
            "VERIFYING DATASET STRUCTURE\n",
            "============================================================\n",
            "✅ /content/drive/MyDrive/Detection/ColabRun_1/dataset/images/train: 122 files\n",
            "✅ /content/drive/MyDrive/Detection/ColabRun_1/dataset/images/val: 31 files\n",
            "✅ /content/drive/MyDrive/Detection/ColabRun_1/dataset/labels/train: 122 files\n",
            "✅ /content/drive/MyDrive/Detection/ColabRun_1/dataset/labels/val: 31 files\n",
            "✅ Dataset configuration file: data.yaml\n",
            "✅ Training set: 122 matching image/label pairs\n",
            "✅ Validation set: 31 matching image/label pairs\n",
            "\n",
            "✅ Dataset structure verification complete!\n",
            "   Dataset is ready for YOLO training!\n",
            "\n",
            "🎯 Dataset ready for training with 122 training images!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Block 7: Model Training\n",
        "Purpose: Train YOLOv11 model for plane detection with optimized settings\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def train_yolo_plane_detection(epochs=250, imgsz=640, batch_size=16):\n",
        "    \"\"\"\n",
        "    Train YOLOv11 model for plane detection\n",
        "\n",
        "    Args:\n",
        "        epochs (int): Number of training epochs\n",
        "        imgsz (int): Input image size\n",
        "        batch_size (int): Batch size for training\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"STARTING YOLOv11 PLANE DETECTION TRAINING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Check GPU availability\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"✅ GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "        device = 0\n",
        "    else:\n",
        "        print(\"⚠️  GPU not available - using CPU (training will be slower)\")\n",
        "        device = 'cpu'\n",
        "\n",
        "    # Initialize YOLOv11 model\n",
        "    print(f\"\\nInitializing YOLOv11 model...\")\n",
        "    # Using nano version for faster training with small dataset\n",
        "    # Consider using 'yolo11s.pt' (small) or 'yolo11m.pt' (medium) for potentially better accuracy\n",
        "    # if you have a larger dataset and more time/resources.\n",
        "    model = YOLO('yolo11n.pt') # Changed back to nano as per conversation flow\n",
        "    print(\"✅ Model initialized\")\n",
        "\n",
        "    # Training parameters optimized for plane detection\n",
        "    print(f\"\\nTraining parameters:\")\n",
        "    print(f\"   Epochs: {epochs}\")\n",
        "    print(f\"   Image size: {imgsz}\")\n",
        "    print(f\"   Batch size: {batch_size}\")\n",
        "    print(f\"   Device: {device}\")\n",
        "\n",
        "    try:\n",
        "        # Start training\n",
        "        print(f\"\\n🚀 Starting training...\")\n",
        "        results = model.train(\n",
        "            # Data and paths\n",
        "            data=f'{COLAB_RUN}/dataset/data.yaml',     # Path to dataset config\n",
        "\n",
        "            # Training parameters\n",
        "            epochs=epochs,                          # Number of training epochs\n",
        "            imgsz=imgsz,                           # Input image size\n",
        "            batch=batch_size,                      # Batch size\n",
        "\n",
        "            # Learning rate settings\n",
        "            lr0=0.01,                              # Initial learning rate\n",
        "            lrf=0.01,                              # Final learning rate (lr0 * lrf)\n",
        "            momentum=0.937,                        # SGD momentum\n",
        "            weight_decay=0.0005,                   # Weight decay for regularization\n",
        "            warmup_epochs=3,                       # Warmup learning rate epochs\n",
        "            warmup_momentum=0.8,                   # Warmup momentum\n",
        "\n",
        "            # Data augmentation (important for satellite imagery)\n",
        "            mosaic=1.0,                            # Mosaic augmentation probability\n",
        "            mixup=0.15,                            # Mixup augmentation probability\n",
        "            copy_paste=0.1,                        # Copy-paste augmentation probability\n",
        "            degrees=0,                             # Rotation range (degrees)\n",
        "            translate=0.1,                         # Translation range\n",
        "            scale=0.5,                             # Scaling range\n",
        "            shear=0,                               # Shear range\n",
        "            perspective=0.0,                       # Perspective transformation range\n",
        "            fliplr=0.5,                            # Horizontal flip probability\n",
        "            flipud=0.0,                            # Vertical flip probability (careful with planes)\n",
        "\n",
        "            # Color augmentations\n",
        "            hsv_h=0.015,                           # Hue augmentation range\n",
        "            hsv_s=0.7,                             # Saturation augmentation range\n",
        "            hsv_v=0.4,                             # Value (brightness) augmentation range\n",
        "\n",
        "            # Optimizer and scheduler\n",
        "            optimizer='auto',                       # Optimizer (auto selects best)\n",
        "            cos_lr=False,                          # Use cosine learning rate scheduler\n",
        "            close_mosaic=10,                       # Disable mosaic in last N epochs\n",
        "\n",
        "            # Hardware and performance\n",
        "            device=device,                         # Training device\n",
        "            workers=8,                             # Number of data loading workers\n",
        "\n",
        "            # Validation and saving\n",
        "            val=True,                              # Validate during training\n",
        "            save=True,                             # Save training checkpoints\n",
        "            save_period=-1,                        # Save checkpoint every N epochs (-1 = only last)\n",
        "            cache=False,                           # Cache images for faster training\n",
        "\n",
        "            # Output settings\n",
        "            project=f'{COLAB_RUN}/runs/detect',        # Project directory (can keep local for Colab run output)\n",
        "            name='plane_detection',                # Experiment name\n",
        "            exist_ok=True,                         # Allow overwriting existing experiment\n",
        "\n",
        "            # Advanced settings\n",
        "            patience=100,                           # Early stopping patience - increased to allow longer training\n",
        "            plots=True,                            # Generate training plots\n",
        "            verbose=True,                          # Verbo se output\n",
        "            seed=0,                                # Random seed for reproducibility\n",
        "            deterministic=True,                    # Deterministic training\n",
        "            single_cls=True,                       # Single class training optimization\n",
        "            rect=False,                            # Rectangular training\n",
        "            resume=False,                          # Resume from last checkpoint\n",
        "            amp=True,                              # Automatic Mixed Precision\n",
        "        )\n",
        "\n",
        "        print(\"\\n✅ Training completed successfully!\")\n",
        "        return model, results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Training failed with error: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def evaluate_model_performance(model):\n",
        "    \"\"\"\n",
        "    Evaluate the trained model performance\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EVALUATING MODEL PERFORMANCE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Run validation\n",
        "    try:\n",
        "        metrics = model.val()\n",
        "\n",
        "        # Extract key metrics\n",
        "        map50 = metrics.box.map50      # mAP at IoU=0.5\n",
        "        map50_95 = metrics.box.map     # mAP at IoU=0.5:0.95\n",
        "        precision = metrics.box.mp     # Mean precision\n",
        "        recall = metrics.box.mr        # Mean recall\n",
        "\n",
        "        print(f\"📊 Model Performance Metrics:\")\n",
        "        print(f\"   mAP@0.5:     {map50:.3f} ({map50*100:.1f}%)\")\n",
        "        print(f\"   mAP@0.5:0.95: {map50_95:.3f} ({map50_95*100:.1f}%)\")\n",
        "        print(f\"   Precision:   {precision:.3f} ({precision*100:.1f}%)\")\n",
        "        print(f\"   Recall:      {recall:.3f} ({recall*100:.1f}%)\")\n",
        "\n",
        "        # Performance interpretation\n",
        "        if map50 > 0.9:\n",
        "            print(\"\\n🎉 Excellent performance! (mAP@0.5 > 90%)\")\n",
        "        elif map50 > 0.8:\n",
        "            print(\"\\n✅ Good performance! (mAP@0.5 > 80%)\")\n",
        "        elif map50 > 0.7:\n",
        "            print(\"\\n👍 Decent performance (mAP@0.5 > 70%)\")\n",
        "        else:\n",
        "            print(\"\\n⚠️  Performance could be improved (mAP@0.5 < 70%)\")\n",
        "            print(\"   Consider training for more epochs or adjusting hyperparameters\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Evaluation failed: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Check if dataset is ready before training\n",
        "# Need to get the count of training files from the directory directly\n",
        "try:\n",
        "    train_files_count = len([f for f in os.listdir(f'{COLAB_RUN}/dataset/images/train') if f.endswith('.jpg')])\n",
        "except FileNotFoundError:\n",
        "    train_files_count = 0\n",
        "    print(f\"⚠️  Training image directory not found: f'{COLAB_RUN}/dataset/images/train\")\n",
        "\n",
        "\n",
        "if 'dataset_ready' in locals() and dataset_ready and train_files_count > 0:\n",
        "    print(\"🎯 Starting model training...\")\n",
        "\n",
        "    # Adjust batch size based on dataset size\n",
        "    dataset_size = train_files_count\n",
        "    if dataset_size < 50:\n",
        "        batch_size = 4\n",
        "        epochs_to_train = 300 # Increased epochs\n",
        "    elif dataset_size < 100:\n",
        "        batch_size = 8\n",
        "        epochs_to_train = 400 # Increased epochs\n",
        "    else:\n",
        "        batch_size = 16\n",
        "        epochs_to_train = 500 # Increased epochs (allowing for potentially longer training)\n",
        "\n",
        "    print(f\"   Adjusted for dataset size ({dataset_size} images):\")\n",
        "    print(f\"   Batch size: {batch_size}, Epochs: {epochs_to_train}\")\n",
        "\n",
        "    # Train the model\n",
        "    model, results = train_yolo_plane_detection(epochs=epochs_to_train, batch_size=batch_size)\n",
        "\n",
        "    if model is not None:\n",
        "        # Evaluate model performance\n",
        "        metrics = evaluate_model_performance(model)\n",
        "\n",
        "        # Save model to Google Drive\n",
        "        model_save_path = f'{COLAB_RUN}/yolo11_plane_detection_model_optimized.pt'\n",
        "        model.save(model_save_path)\n",
        "        print(f\"\\n💾 Model saved to: {model_save_path}\")\n",
        "        print(\"✅ Training pipeline completed successfully!\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ Training failed - model not available\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Dataset not ready or no training files available\")\n",
        "    print(\"   Please run the previous blocks to prepare your dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GoHUz8q29gn",
        "outputId": "8abff150-1b6b-4818-c599-d866312bf2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Starting model training...\n",
            "   Adjusted for dataset size (122 images):\n",
            "   Batch size: 16, Epochs: 500\n",
            "============================================================\n",
            "STARTING YOLOv11 PLANE DETECTION TRAINING\n",
            "============================================================\n",
            "✅ GPU available: Tesla T4\n",
            "   GPU Memory: 15.8 GB\n",
            "\n",
            "Initializing YOLOv11 model...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4/5.4MB 81.1MB/s 0.1s\n",
            "✅ Model initialized\n",
            "\n",
            "Training parameters:\n",
            "   Epochs: 500\n",
            "   Image size: 640\n",
            "   Batch size: 16\n",
            "   Device: 0\n",
            "\n",
            "🚀 Starting training...\n",
            "Ultralytics 8.3.188 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Detection/ColabRun_1/dataset/data.yaml, degrees=0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=500, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=plane_detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/Detection/ColabRun_1/runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/Detection/ColabRun_1/runs/detect/plane_detection, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=True, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1/755.1KB 21.8MB/s 0.0s\n",
            "Overriding class names with single class.\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 0.5±0.2 MB/s, size: 1.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Detection/ColabRun_1/dataset/labels/train... 122 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 122/122 123.7it/s 1.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Detection/ColabRun_1/dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.3±0.9 ms, read: 0.8±0.1 MB/s, size: 1.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Detection/ColabRun_1/dataset/labels/val... 31 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 31/31 77.1it/s 0.4s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Detection/ColabRun_1/dataset/labels/val.cache\n",
            "Plotting labels to /content/drive/MyDrive/Detection/ColabRun_1/runs/detect/plane_detection/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Detection/ColabRun_1/runs/detect/plane_detection\u001b[0m\n",
            "Starting training for 500 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/500      2.28G      1.623      2.618      2.047         37        640: 100% ━━━━━━━━━━━━ 8/8 0.36it/s 22.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.28it/s 3.5s\n",
            "                   all         31         31    0.00333          1     0.0594     0.0262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/500      2.68G      1.067       2.38      1.597         32        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31    0.00333          1      0.772      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/500       2.7G     0.7823      1.911      1.317         32        640: 100% ━━━━━━━━━━━━ 8/8 2.9it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31    0.00333          1      0.708      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/500      2.71G     0.7559      1.573      1.292         25        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n",
            "                   all         31         31    0.00333          1      0.874       0.66\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/500      2.73G     0.8005      1.314       1.31         37        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.901      0.585      0.905      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/500      2.74G     0.7968      1.175      1.283         38        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.739      0.935      0.841      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/500      2.77G     0.7009     0.9892      1.197         37        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.697      0.871      0.866      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/500      2.77G     0.6815      0.986      1.168         35        640: 100% ━━━━━━━━━━━━ 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         31         31      0.549      0.613      0.508      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/500      2.79G     0.7463     0.9618      1.275         40        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
            "                   all         31         31      0.433      0.484      0.469        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/500      2.81G     0.6652      0.937      1.178         33        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.768      0.427      0.572      0.305\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/500      2.83G     0.6493     0.8564      1.175         36        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.671      0.258      0.295      0.148\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/500      2.84G     0.7367     0.8942      1.218         31        640: 100% ━━━━━━━━━━━━ 8/8 4.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.177      0.484      0.196      0.122\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/500      2.85G     0.6906     0.8795      1.192         30        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31      0.376      0.516      0.505      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/500      2.87G     0.6306     0.8385      1.159         33        640: 100% ━━━━━━━━━━━━ 8/8 4.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
            "                   all         31         31      0.207      0.452      0.226      0.126\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/500      2.88G      0.676     0.8111      1.209         34        640: 100% ━━━━━━━━━━━━ 8/8 4.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.241      0.355      0.277      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/500       2.9G     0.6002     0.7573       1.14         30        640: 100% ━━━━━━━━━━━━ 8/8 4.6it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.334      0.677      0.469      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/500      2.91G      0.601      0.766      1.157         38        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.315      0.608      0.437      0.319\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/500      2.93G     0.6002     0.7594      1.149         27        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.306      0.516      0.349      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/500      2.94G     0.5694     0.7448      1.113         25        640: 100% ━━━━━━━━━━━━ 8/8 3.9it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
            "                   all         31         31      0.551      0.515      0.504      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/500      2.96G     0.6545     0.8269      1.206         51        640: 100% ━━━━━━━━━━━━ 8/8 4.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n",
            "                   all         31         31      0.373      0.806       0.39      0.263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/500      2.97G     0.5681     0.6978       1.12         32        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31      0.381      0.935      0.501      0.286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/500      2.99G     0.6859     0.7804      1.199         31        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
            "                   all         31         31      0.453      0.803      0.462      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/500         3G     0.6703     0.7598      1.164         31        640: 100% ━━━━━━━━━━━━ 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         31         31      0.567       0.76      0.608      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/500      3.02G     0.6028     0.7234      1.144         32        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.446      0.839      0.537      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/500      3.03G     0.6653     0.7114      1.191         38        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31       0.49      0.935      0.875      0.737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/500      3.05G     0.6166     0.6661      1.151         26        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.641      0.935      0.891      0.648\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/500      3.06G     0.6115     0.6596      1.175         41        640: 100% ━━━━━━━━━━━━ 8/8 2.6it/s 3.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.837      0.806      0.921      0.756\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/500      3.08G     0.5755     0.6283      1.111         29        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
            "                   all         31         31      0.749      0.742      0.881      0.758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/500      3.09G     0.6254     0.6833      1.171         28        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all         31         31      0.631      0.774      0.752      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/500      3.11G     0.5876     0.6512      1.124         34        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         31         31      0.304      0.774      0.334      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/500      3.12G      0.591     0.6513      1.132         35        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
            "                   all         31         31      0.633      0.677      0.723      0.568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/500      3.13G     0.5522     0.5987      1.118         34        640: 100% ━━━━━━━━━━━━ 8/8 3.4it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.832      0.871      0.911      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/500      3.15G     0.5711     0.6507      1.148         46        640: 100% ━━━━━━━━━━━━ 8/8 2.7it/s 3.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.577      0.839      0.849      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/500      3.17G     0.5979     0.6333      1.171         31        640: 100% ━━━━━━━━━━━━ 8/8 3.9it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         31         31      0.654      0.903      0.863       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/500      3.18G     0.5107     0.5444      1.086         36        640: 100% ━━━━━━━━━━━━ 8/8 5.0it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31      0.586      0.903        0.7       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/500      3.19G     0.5808      0.572      1.128         37        640: 100% ━━━━━━━━━━━━ 8/8 4.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31      0.762      0.903      0.941      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/500      3.21G     0.6135     0.6521      1.135         38        640: 100% ━━━━━━━━━━━━ 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.529      0.774      0.704       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/500      3.22G      0.596     0.6071      1.165         26        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         31         31      0.399      0.968      0.431      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/500      3.24G     0.5727      0.561       1.12         32        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
            "                   all         31         31          1      0.867      0.981      0.914\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/500      3.25G     0.5554     0.5618      1.118         40        640: 100% ━━━━━━━━━━━━ 8/8 4.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
            "                   all         31         31      0.994          1      0.995      0.793\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/500      3.27G     0.5243     0.5565      1.106         26        640: 100% ━━━━━━━━━━━━ 8/8 5.0it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n",
            "                   all         31         31      0.982      0.968      0.992      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/500      3.28G     0.5221     0.5222       1.07         27        640: 100% ━━━━━━━━━━━━ 8/8 2.1it/s 3.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n",
            "                   all         31         31      0.908      0.935       0.97      0.881\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/500       3.3G     0.5365     0.5467      1.113         34        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
            "                   all         31         31      0.867      0.968      0.964       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/500      3.31G     0.5679     0.5393      1.102         27        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.796      0.677      0.781      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/500      3.33G     0.4961     0.5256       1.07         25        640: 100% ━━━━━━━━━━━━ 8/8 4.6it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.5s\n",
            "                   all         31         31      0.759      0.813      0.806      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/500      3.34G     0.5397     0.5492      1.096         40        640: 100% ━━━━━━━━━━━━ 8/8 2.9it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.811      0.831      0.922      0.856\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/500      3.36G     0.5508     0.5834      1.111         32        640: 100% ━━━━━━━━━━━━ 8/8 2.9it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31      0.924      0.806      0.948       0.92\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/500      3.37G     0.4871     0.5245      1.078         32        640: 100% ━━━━━━━━━━━━ 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n",
            "                   all         31         31          1      0.993      0.995      0.952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/500      3.39G     0.4763     0.4912      1.074         37        640: 100% ━━━━━━━━━━━━ 8/8 4.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.989          1      0.995      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/500       3.4G     0.4626     0.4691      1.062         37        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.931          1      0.988      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/500      3.42G     0.5239     0.5301      1.136         33        640: 100% ━━━━━━━━━━━━ 8/8 2.5it/s 3.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         31         31      0.986          1      0.995       0.92\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/500      3.43G     0.4864     0.4788      1.072         27        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
            "                   all         31         31      0.966      0.968      0.992      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/500      3.45G      0.429     0.4252      1.044         31        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.881      0.935      0.978      0.866\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/500      3.46G     0.5499     0.5118      1.131         37        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31      0.849      0.909      0.951      0.821\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/500      3.48G     0.4449     0.4538      1.046         37        640: 100% ━━━━━━━━━━━━ 8/8 3.9it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n",
            "                   all         31         31      0.989          1      0.995      0.929\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/500      3.49G     0.4936     0.4773      1.083         32        640: 100% ━━━━━━━━━━━━ 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.941      0.935      0.981      0.923\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/500      3.51G     0.4971     0.5048      1.091         34        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31      0.871      0.968      0.989      0.943\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/500      3.52G     0.4821     0.4942       1.06         38        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31      0.932          1      0.988      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/500      3.54G     0.4973     0.4995      1.081         32        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.976\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/500      3.55G     0.4713     0.4462      1.059         28        640: 100% ━━━━━━━━━━━━ 8/8 3.4it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         31         31      0.997          1      0.995      0.942\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/500      3.56G     0.5253     0.5061      1.093         35        640: 100% ━━━━━━━━━━━━ 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n",
            "                   all         31         31      0.997          1      0.995      0.947\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/500      3.58G     0.5121     0.5283      1.085         31        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
            "                   all         31         31      0.997          1      0.995      0.941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/500      3.59G     0.5387     0.5339      1.111         30        640: 100% ━━━━━━━━━━━━ 8/8 3.9it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.997          1      0.995      0.935\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/500      3.61G     0.4688     0.4546      1.036         29        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all         31         31      0.961          1      0.994      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/500      3.62G     0.4731     0.4657      1.052         35        640: 100% ━━━━━━━━━━━━ 8/8 3.9it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.995          1      0.995      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/500      3.64G     0.4402      0.426      1.033         33        640: 100% ━━━━━━━━━━━━ 8/8 3.1it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.979          1      0.995      0.922\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/500      3.65G     0.4519     0.4223      1.052         28        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         31         31      0.994          1      0.995      0.924\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/500      3.67G     0.4413     0.4632      1.044         42        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.938\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/500      3.68G     0.4375     0.4562      1.041         30        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/500       3.7G     0.4642     0.4629      1.084         34        640: 100% ━━━━━━━━━━━━ 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.969          1      0.995      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/500      3.71G     0.4149     0.4266      1.027         31        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.741          1      0.982      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/500      3.73G     0.4228     0.4213      1.024         32        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31       0.84      0.968      0.983        0.9\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/500      3.74G     0.4647     0.4572      1.075         36        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31          1      0.996      0.995      0.922\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/500      3.76G     0.4731     0.4506       1.05         43        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.937      0.935      0.967        0.9\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/500      3.77G     0.4359     0.4586      1.039         39        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31      0.911      0.968      0.985      0.929\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/500      3.79G     0.4358     0.4175      1.056         28        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.995          1      0.995       0.95\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/500       3.8G     0.5019     0.4474      1.088         35        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         31         31      0.995          1      0.995      0.976\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/500      3.82G     0.4422     0.4063      1.026         37        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
            "                   all         31         31      0.971      0.935      0.992      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/500      3.83G      0.467     0.4541      1.053         44        640: 100% ━━━━━━━━━━━━ 8/8 3.3it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         31         31      0.997          1      0.995      0.951\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/500      3.85G     0.4206     0.3982     0.9958         35        640: 100% ━━━━━━━━━━━━ 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.971          1      0.995      0.923\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/500      3.86G     0.4553     0.4475      1.043         41        640: 100% ━━━━━━━━━━━━ 8/8 3.3it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         31         31      0.989          1      0.995      0.944\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/500      3.88G     0.4565     0.4399      1.085         32        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.997          1      0.995      0.984\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/500      3.89G     0.4549     0.4535      1.052         36        640: 100% ━━━━━━━━━━━━ 8/8 4.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.998          1      0.995      0.972\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/500      3.91G      0.476     0.4634      1.081         41        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31       0.99          1      0.995      0.965\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/500      3.92G     0.4368     0.4185      1.033         36        640: 100% ━━━━━━━━━━━━ 8/8 2.9it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n",
            "                   all         31         31      0.812      0.742      0.843        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/500      3.94G     0.4652     0.4204      1.074         40        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.515      0.871      0.646       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/500      3.95G     0.4703     0.4472      1.046         40        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.846      0.935      0.915      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/500      3.96G     0.4291      0.401      1.026         23        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31      0.997          1      0.995      0.961\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/500      3.98G     0.4343     0.4191       1.03         34        640: 100% ━━━━━━━━━━━━ 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.6s\n",
            "                   all         31         31      0.995          1      0.995      0.969\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/500      3.99G     0.4158     0.3848      1.008         32        640: 100% ━━━━━━━━━━━━ 8/8 2.7it/s 3.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.4it/s 0.7s\n",
            "                   all         31         31      0.995          1      0.995      0.969\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/500      4.01G     0.4022     0.3752      1.021         46        640: 100% ━━━━━━━━━━━━ 8/8 3.1it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.905          1      0.995      0.983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/500      4.02G     0.4436     0.4169      1.055         32        640: 100% ━━━━━━━━━━━━ 8/8 3.1it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n",
            "                   all         31         31      0.927      0.814      0.969      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/500      4.04G     0.4174     0.4054       1.04         32        640: 100% ━━━━━━━━━━━━ 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.938      0.806      0.927      0.882\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/500      4.05G       0.46     0.4436      1.071         39        640: 100% ━━━━━━━━━━━━ 8/8 3.0it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.936      0.949      0.989      0.936\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/500      4.07G       0.41     0.3856      1.035         33        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.966\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/500      4.08G     0.4717     0.4351      1.075         43        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.964\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/500       4.1G     0.4416     0.4156      1.046         34        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.991\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/500      4.11G     0.4186     0.3924      1.008         42        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995       0.99\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/500      4.13G     0.4317     0.4034      1.061         37        640: 100% ━━━━━━━━━━━━ 8/8 2.6it/s 3.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3it/s 0.8s\n",
            "                   all         31         31      0.995          1      0.995      0.979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/500      4.14G     0.4258     0.4002       1.03         32        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
            "                   all         31         31      0.995          1      0.995      0.991\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    101/500      4.16G     0.4996     0.4469      1.078         34        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n",
            "                   all         31         31      0.967          1      0.994      0.994\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    102/500      4.17G     0.4134      0.381      1.033         35        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
            "                   all         31         31      0.908          1      0.969      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    103/500      4.19G      0.422      0.395      1.032         32        640: 100% ━━━━━━━━━━━━ 8/8 4.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.907      0.968      0.971      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    104/500       4.2G     0.4185     0.3947      1.016         36        640: 100% ━━━━━━━━━━━━ 8/8 2.7it/s 3.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
            "                   all         31         31      0.993          1      0.995      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    105/500      4.22G     0.4378     0.4232      1.056         33        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         31         31      0.956      0.935      0.983      0.967\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    106/500      4.23G     0.3776     0.3617     0.9856         26        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31          1      0.925      0.987      0.949\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    107/500      4.25G      0.444     0.4233      1.045         36        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n",
            "                   all         31         31      0.959      0.935      0.988      0.956\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    108/500      4.26G     0.4464     0.4097      1.031         30        640: 100% ━━━━━━━━━━━━ 8/8 3.9it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         31         31      0.998          1      0.995      0.986\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    109/500      4.28G     0.4326     0.4702      1.043         33        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.942\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    110/500      4.29G      0.419     0.4172      1.047         33        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.954      0.968      0.988      0.913\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    111/500       4.3G      0.404      0.381      1.029         29        640: 100% ━━━━━━━━━━━━ 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.828      0.968       0.98      0.915\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    112/500      4.32G     0.4399       0.41      1.038         32        640: 100% ━━━━━━━━━━━━ 8/8 3.4it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n",
            "                   all         31         31      0.851      0.968       0.99      0.925\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    113/500      4.33G     0.4714     0.4144      1.065         30        640: 100% ━━━━━━━━━━━━ 8/8 2.7it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2it/s 0.8s\n",
            "                   all         31         31       0.91      0.982      0.991      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    114/500      4.35G     0.4336     0.4059      1.062         25        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.829       0.94       0.97      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    115/500      4.37G     0.4363     0.4045      1.037         39        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all         31         31       0.93          1      0.995      0.944\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    116/500      4.38G     0.3934     0.3618       1.02         30        640: 100% ━━━━━━━━━━━━ 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
            "                   all         31         31      0.644          1       0.89      0.826\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    117/500      4.39G     0.4057     0.3738       1.04         35        640: 100% ━━━━━━━━━━━━ 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.5s\n",
            "                   all         31         31      0.675      0.935      0.854       0.77\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    118/500      4.41G     0.3949     0.3761     0.9928         26        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n",
            "                   all         31         31      0.912      0.968      0.991      0.914\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    119/500      4.43G     0.4481     0.4198      1.053         31        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31      0.945          1      0.994      0.978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    120/500      4.44G     0.4023     0.4102      1.041         38        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.889      0.935      0.952      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    121/500      4.45G     0.4154     0.3947      1.014         38        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31       0.89      0.935       0.94      0.792\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    122/500      4.47G     0.4206     0.4184      1.039         28        640: 100% ━━━━━━━━━━━━ 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n",
            "                   all         31         31      0.968          1      0.995      0.948\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    123/500      4.48G     0.3435     0.3412     0.9533         35        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
            "                   all         31         31       0.99          1      0.995       0.97\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    124/500       4.5G     0.4141     0.4125      1.028         36        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
            "                   all         31         31       0.98          1      0.995      0.988\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    125/500      4.51G     0.4056     0.3947      1.032         34        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         31         31      0.754          1      0.995      0.953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    126/500      4.53G     0.4176     0.3821      1.029         38        640: 100% ━━━━━━━━━━━━ 8/8 4.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.986\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    127/500      4.54G     0.3988     0.3449      1.019         24        640: 100% ━━━━━━━━━━━━ 8/8 3.9it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n",
            "                   all         31         31      0.998          1      0.995      0.958\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    128/500      4.56G     0.4074     0.3622      1.045         38        640: 100% ━━━━━━━━━━━━ 8/8 3.3it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n",
            "                   all         31         31      0.997          1      0.995      0.963\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    129/500      4.57G     0.4628      0.408      1.063         38        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
            "                   all         31         31      0.991          1      0.995       0.94\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    130/500      4.59G     0.4197     0.4154      1.046         47        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
            "                   all         31         31      0.859      0.979      0.986      0.953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    131/500       4.6G     0.3792     0.3609     0.9971         29        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.955      0.903      0.972      0.937\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    132/500      4.62G     0.4364     0.4049      1.042         32        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31          1      0.928      0.989      0.982\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    133/500      4.63G      0.418     0.4006      1.041         33        640: 100% ━━━━━━━━━━━━ 8/8 3.0it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.4it/s 0.7s\n",
            "                   all         31         31      0.995          1      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    134/500      4.65G     0.3966     0.3436      1.018         37        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         31         31      0.927      0.871      0.971      0.941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    135/500      4.66G     0.4198     0.4057      1.037         43        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.882      0.935      0.977      0.924\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    136/500      4.68G     0.4526     0.3822      1.075         30        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n",
            "                   all         31         31      0.994          1      0.995      0.983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    137/500      4.69G     0.3684     0.3386      1.003         32        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
            "                   all         31         31      0.987          1      0.995      0.961\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    138/500      4.71G     0.4172     0.3913      1.048         38        640: 100% ━━━━━━━━━━━━ 8/8 3.3it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         31         31      0.986          1      0.995      0.956\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    139/500      4.72G     0.4167     0.4385      1.038         40        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.938      0.975      0.993      0.978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    140/500      4.73G     0.4078     0.3807       1.03         41        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.938      0.969      0.993      0.949\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    141/500      4.75G     0.3955     0.3709      1.001         38        640: 100% ━━━━━━━━━━━━ 8/8 4.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.984          1      0.995       0.97\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    142/500      4.76G      0.379     0.3486     0.9884         29        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.988      0.968      0.993       0.96\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    143/500      4.78G     0.3779      0.357      1.005         30        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.4it/s 0.7s\n",
            "                   all         31         31      0.989          1      0.995      0.969\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    144/500      4.79G     0.3952     0.3775      1.015         39        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n",
            "                   all         31         31      0.988          1      0.995      0.979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    145/500      4.81G     0.3939     0.3521       1.03         31        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
            "                   all         31         31      0.994          1      0.995      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    146/500      4.82G      0.363     0.3335      1.017         37        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
            "                   all         31         31      0.997          1      0.995      0.974\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    147/500      4.84G     0.3948     0.3649      1.018         38        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         31         31      0.993          1      0.995      0.983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    148/500      4.85G     0.4171     0.3859      1.054         32        640: 100% ━━━━━━━━━━━━ 8/8 2.5it/s 3.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.998          1      0.995      0.973\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    149/500      4.87G     0.3933     0.3669      1.014         32        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n",
            "                   all         31         31          1      0.928      0.991      0.938\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    150/500      4.88G     0.3537     0.3367     0.9926         31        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.968      0.977      0.994       0.96\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    151/500       4.9G     0.3924     0.3831      1.017         30        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
            "                   all         31         31      0.996          1      0.995      0.984\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    152/500      4.91G     0.3605     0.3446     0.9807         30        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n",
            "                   all         31         31      0.997          1      0.995      0.965\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    153/500      4.93G     0.3686     0.3839     0.9956         36        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n",
            "                   all         31         31      0.996          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    154/500      4.94G     0.3864     0.3874      1.012         34        640: 100% ━━━━━━━━━━━━ 8/8 5.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.997          1      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    155/500      4.96G     0.3417     0.3403     0.9894         35        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    156/500      4.97G     0.4061     0.3537      1.017         26        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995       0.97\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    157/500      4.99G     0.3533     0.3414     0.9955         36        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31       0.99          1      0.995      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    158/500         5G     0.3995     0.3609       1.02         29        640: 100% ━━━━━━━━━━━━ 8/8 3.1it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         31         31      0.993          1      0.995      0.971\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    159/500      5.02G     0.4269     0.4033      1.049         35        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    160/500      5.03G     0.4124     0.3837      1.038         41        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
            "                   all         31         31          1      0.998      0.995      0.957\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    161/500      5.05G     0.4428     0.4154      1.059         33        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n",
            "                   all         31         31      0.954      0.968      0.974       0.93\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    162/500      5.06G     0.4108      0.392       1.04         40        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n",
            "                   all         31         31      0.881      0.935      0.958      0.879\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    163/500      5.08G     0.3755     0.3437      1.013         32        640: 100% ━━━━━━━━━━━━ 8/8 3.1it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.5s\n",
            "                   all         31         31      0.956      0.968      0.988      0.944\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    164/500      5.09G      0.373     0.3548      1.018         38        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.831          1      0.981      0.978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    165/500       5.1G     0.4399     0.4117      1.058         29        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.795          1      0.961      0.942\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    166/500      5.12G     0.4677     0.4242      1.083         49        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.854      0.946      0.985      0.935\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    167/500      5.13G     0.4219     0.3756      1.035         37        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n",
            "                   all         31         31      0.958          1      0.994      0.978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    168/500      5.15G      0.396     0.3665      1.033         38        640: 100% ━━━━━━━━━━━━ 8/8 3.4it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         31         31      0.993          1      0.995      0.978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    169/500      5.16G      0.367     0.3346      1.018         32        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.4s\n",
            "                   all         31         31      0.997          1      0.995       0.98\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    170/500      5.18G     0.3947     0.3873      1.039         26        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.988\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    171/500      5.19G       0.37     0.3517      1.006         37        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    172/500      5.21G     0.3641     0.3466     0.9987         46        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    173/500      5.22G     0.3649     0.3275      1.018         31        640: 100% ━━━━━━━━━━━━ 8/8 3.3it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.5s\n",
            "                   all         31         31      0.985          1      0.995      0.982\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    174/500      5.24G     0.3654     0.3313      1.002         43        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.902          1      0.991      0.958\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    175/500      5.25G     0.3957     0.3736      1.004         34        640: 100% ━━━━━━━━━━━━ 8/8 3.9it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n",
            "                   all         31         31      0.996      0.935      0.987      0.953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    176/500      5.27G      0.372     0.3344     0.9899         41        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31      0.966      0.924      0.981      0.955\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    177/500      5.28G     0.3529     0.3339     0.9839         31        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
            "                   all         31         31      0.936      0.935      0.986      0.977\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    178/500       5.3G     0.3909     0.3754      1.034         39        640: 100% ━━━━━━━━━━━━ 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n",
            "                   all         31         31      0.915      0.935      0.973      0.943\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    179/500      5.31G     0.3815     0.3729      1.012         28        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
            "                   all         31         31       0.98      0.935      0.973      0.928\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    180/500      5.33G     0.3706     0.3445      1.025         34        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
            "                   all         31         31      0.979      0.935      0.973      0.919\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    181/500      5.34G     0.3433     0.3237     0.9708         34        640: 100% ━━━━━━━━━━━━ 8/8 4.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
            "                   all         31         31      0.778      0.968      0.961      0.922\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    182/500      5.36G     0.3524     0.3237      0.989         34        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n",
            "                   all         31         31      0.939      0.996      0.993      0.963\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    183/500      5.37G     0.4572     0.3701      1.065         32        640: 100% ━━━━━━━━━━━━ 8/8 2.9it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         31         31      0.909          1      0.991      0.984\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    184/500      5.39G     0.3843     0.3556      1.036         33        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31      0.947      0.968      0.992       0.99\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    185/500       5.4G     0.3629     0.3445     0.9829         34        640: 100% ━━━━━━━━━━━━ 8/8 4.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n",
            "                   all         31         31      0.993          1      0.995       0.98\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    186/500      5.42G     0.3996     0.3574      1.017         28        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31          1      0.932      0.975      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    187/500      5.43G     0.3606     0.3513      0.999         38        640: 100% ━━━━━━━━━━━━ 8/8 4.9it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n",
            "                   all         31         31      0.992          1      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    188/500      5.45G     0.3759     0.3537      1.011         32        640: 100% ━━━━━━━━━━━━ 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.997          1      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    189/500      5.46G     0.3575     0.3286      1.004         37        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.996          1      0.995      0.989\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    190/500      5.47G     0.3524     0.3133     0.9998         36        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995       0.99\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    191/500      5.49G      0.379     0.3353      1.015         31        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
            "                   all         31         31      0.998          1      0.995      0.978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    192/500      5.51G     0.3656     0.3246     0.9979         34        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    193/500      5.52G     0.4153     0.3799      1.027         36        640: 100% ━━━━━━━━━━━━ 8/8 2.9it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    194/500      5.54G     0.3829     0.3597      1.018         34        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    195/500      5.55G      0.379     0.3738      1.016         31        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
            "                   all         31         31      0.997          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    196/500      5.56G     0.3637     0.3122      0.967         39        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n",
            "                   all         31         31      0.995          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    197/500      5.58G     0.3595     0.3324     0.9917         31        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    198/500      5.59G     0.4111     0.3971       1.04         36        640: 100% ━━━━━━━━━━━━ 8/8 2.7it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    199/500      5.61G     0.3827     0.3769       1.03         38        640: 100% ━━━━━━━━━━━━ 8/8 4.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    200/500      5.62G     0.3403     0.3467     0.9854         35        640: 100% ━━━━━━━━━━━━ 8/8 4.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.991\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    201/500      5.64G     0.3774     0.3831      1.015         34        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.6it/s 0.2s\n",
            "                   all         31         31      0.996          1      0.995      0.991\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    202/500      5.65G     0.3439     0.3351     0.9861         35        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31       0.98          1      0.995      0.988\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    203/500      5.67G     0.3494     0.3533     0.9884         36        640: 100% ━━━━━━━━━━━━ 8/8 3.1it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
            "                   all         31         31      0.992          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    204/500      5.68G     0.3575      0.347      1.001         32        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.988\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    205/500       5.7G     0.3406     0.3347     0.9804         35        640: 100% ━━━━━━━━━━━━ 8/8 4.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.982      0.968      0.994      0.979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    206/500      5.71G     0.3346     0.3171      0.976         31        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
            "                   all         31         31          1      0.995      0.995      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    207/500      5.73G     0.3454     0.3382      1.011         34        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         31         31      0.973      0.968      0.991      0.946\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    208/500      5.74G      0.375     0.3451      1.012         41        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.992          1      0.995      0.977\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    209/500      5.76G     0.3559     0.3341     0.9904         33        640: 100% ━━━━━━━━━━━━ 8/8 4.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.3it/s 0.2s\n",
            "                   all         31         31       0.93          1      0.995       0.97\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    210/500      5.77G     0.3874     0.3688      1.006         36        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.896          1      0.995      0.981\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    211/500      5.79G     0.3875      0.367       1.03         29        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.994          1      0.995      0.979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    212/500       5.8G     0.3716     0.3531      1.012         37        640: 100% ━━━━━━━━━━━━ 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.995          1      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    213/500      5.82G     0.3408      0.352     0.9997         25        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.977\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    214/500      5.83G     0.3511     0.3539     0.9891         34        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.988\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    215/500      5.85G     0.3497     0.3506     0.9977         32        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.5it/s 0.2s\n",
            "                   all         31         31      0.998          1      0.995      0.977\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    216/500      5.86G      0.337     0.3372      1.015         26        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    217/500      5.88G     0.3416     0.3333     0.9782         36        640: 100% ━━━━━━━━━━━━ 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         31         31      0.998          1      0.995       0.99\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    218/500      5.89G     0.3556     0.3168     0.9919         28        640: 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    219/500      5.91G     0.3493     0.3324      1.013         29        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
            "                   all         31         31      0.998          1      0.995      0.988\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    220/500      5.92G     0.3281     0.3063     0.9836         39        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    221/500      5.93G     0.3561     0.3314          1         38        640: 100% ━━━━━━━━━━━━ 8/8 4.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    222/500      5.95G     0.3521       0.31     0.9841         37        640: 100% ━━━━━━━━━━━━ 8/8 3.4it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    223/500      5.96G       0.36     0.3446      1.009         39        640: 100% ━━━━━━━━━━━━ 8/8 3.3it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    224/500      5.98G     0.3648     0.3495          1         35        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
            "                   all         31         31      0.997          1      0.995      0.987\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    225/500      5.99G     0.3465     0.3097     0.9939         33        640: 100% ━━━━━━━━━━━━ 8/8 4.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n",
            "                   all         31         31      0.997          1      0.995      0.982\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    226/500      6.01G     0.3817     0.3138      1.008         48        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    227/500      6.02G     0.3777     0.3216      1.003         32        640: 100% ━━━━━━━━━━━━ 8/8 3.4it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         31         31      0.998          1      0.995      0.983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    228/500      6.04G     0.3634     0.3446      1.017         31        640: 100% ━━━━━━━━━━━━ 8/8 3.3it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.995          1      0.995       0.97\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    229/500      6.05G      0.356     0.3113     0.9997         40        640: 100% ━━━━━━━━━━━━ 8/8 4.0it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all         31         31      0.993          1      0.995      0.983\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    230/500      6.07G     0.3474     0.3211     0.9739         39        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.991          1      0.995      0.982\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    231/500      6.08G     0.3464     0.3078      0.977         36        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31      0.983          1      0.995      0.976\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    232/500       6.1G     0.4128     0.3583      1.046         36        640: 100% ━━━━━━━━━━━━ 8/8 3.4it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         31         31      0.989          1      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    233/500      6.11G     0.3472     0.3095     0.9688         29        640: 100% ━━━━━━━━━━━━ 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31      0.993          1      0.995      0.984\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    234/500      6.13G     0.3721     0.3538      1.012         37        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.975\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    235/500      6.14G     0.3495     0.3308      1.001         35        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.991\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    236/500      6.16G     0.3427     0.3222     0.9866         40        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    237/500      6.17G     0.3472     0.3052     0.9971         40        640: 100% ━━━━━━━━━━━━ 8/8 2.9it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    238/500      6.19G     0.3405     0.3049     0.9744         24        640: 100% ━━━━━━━━━━━━ 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.991\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    239/500       6.2G     0.3647     0.3401      1.019         31        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    240/500      6.22G     0.3179     0.2758      0.949         39        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.4it/s 0.2s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    241/500      6.23G     0.3639     0.3377       1.01         47        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    242/500      6.25G      0.337     0.3192     0.9862         38        640: 100% ━━━━━━━━━━━━ 8/8 3.1it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    243/500      6.26G     0.3325      0.309     0.9861         27        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
            "                   all         31         31      0.996          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    244/500      6.27G     0.3505     0.3017      0.992         29        640: 100% ━━━━━━━━━━━━ 8/8 4.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n",
            "                   all         31         31      0.996          1      0.995      0.988\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    245/500      6.29G     0.3263      0.313     0.9813         28        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31      0.996          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    246/500       6.3G     0.3222     0.3114     0.9749         47        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    247/500      6.32G     0.3616     0.3379      1.006         41        640: 100% ━━━━━━━━━━━━ 8/8 2.8it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31      0.996          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    248/500      6.33G     0.3648     0.3077      1.006         38        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31      0.989          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    249/500      6.35G     0.3018     0.2945     0.9519         37        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         31         31      0.977          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    250/500      6.36G     0.3329     0.3053     0.9796         42        640: 100% ━━━━━━━━━━━━ 8/8 4.1it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         31         31      0.909          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    251/500      6.38G     0.3528     0.3035      1.002         37        640: 100% ━━━━━━━━━━━━ 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.988          1      0.995      0.989\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    252/500      6.39G     0.3451     0.3064      1.008         32        640: 100% ━━━━━━━━━━━━ 8/8 3.1it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31      0.996          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    253/500      6.41G     0.3486     0.3389      1.017         38        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31      0.989          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    254/500      6.42G     0.3234     0.3145     0.9738         33        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.974          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    255/500      6.44G     0.3167     0.3035     0.9796         35        640: 100% ━━━━━━━━━━━━ 8/8 4.5it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.4s\n",
            "                   all         31         31      0.968          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    256/500      6.45G     0.3634      0.347      1.017         37        640: 100% ━━━━━━━━━━━━ 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         31         31      0.968          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    257/500      6.47G     0.3602     0.3517      1.018         34        640: 100% ━━━━━━━━━━━━ 8/8 3.4it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.991          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    258/500      6.48G     0.3819     0.3659      1.037         30        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.993\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    259/500       6.5G     0.3295     0.3132     0.9963         28        640: 100% ━━━━━━━━━━━━ 8/8 4.3it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    260/500      6.51G     0.3091     0.3224     0.9887         30        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
            "                   all         31         31      0.968      0.961      0.989       0.97\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    261/500      6.53G     0.3564     0.3303      1.019         32        640: 100% ━━━━━━━━━━━━ 8/8 3.1it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         31         31      0.978      0.968      0.994      0.978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    262/500      6.54G     0.3134     0.3271     0.9799         31        640: 100% ━━━━━━━━━━━━ 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.923      0.968      0.988      0.974\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    263/500      6.55G     0.3332     0.3118     0.9795         38        640: 100% ━━━━━━━━━━━━ 8/8 3.9it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n",
            "                   all         31         31      0.863      0.935      0.974      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    264/500      6.57G      0.318     0.2792     0.9678         33        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
            "                   all         31         31      0.876      0.968      0.976      0.968\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    265/500      6.58G     0.3423     0.3012     0.9899         44        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         31         31      0.881      0.968      0.987       0.98\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    266/500       6.6G     0.3024     0.2913      0.967         27        640: 100% ━━━━━━━━━━━━ 8/8 3.1it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         31         31      0.904      0.968      0.991      0.986\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    267/500      6.62G     0.3437     0.3278      1.007         30        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.981          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    268/500      6.63G     0.2839     0.2655     0.9367         35        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
            "                   all         31         31      0.994          1      0.995      0.992\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    269/500      6.64G     0.3445      0.299       1.02         36        640: 100% ━━━━━━━━━━━━ 8/8 4.2it/s 1.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    270/500      6.66G     0.3228      0.303     0.9986         28        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    271/500      6.67G     0.2801     0.2612     0.9611         36        640: 100% ━━━━━━━━━━━━ 8/8 2.9it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    272/500      6.69G     0.3289     0.3245     0.9789         51        640: 100% ━━━━━━━━━━━━ 8/8 4.4it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 100 epochs. Best results observed at epoch 172, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=100) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "272 epochs completed in 0.232 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/Detection/ColabRun_1/runs/detect/plane_detection/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/Detection/ColabRun_1/runs/detect/plane_detection/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/Detection/ColabRun_1/runs/detect/plane_detection/weights/best.pt...\n",
            "Ultralytics 8.3.188 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "Speed: 0.2ms preprocess, 3.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Detection/ColabRun_1/runs/detect/plane_detection\u001b[0m\n",
            "\n",
            "✅ Training completed successfully!\n",
            "\n",
            "============================================================\n",
            "EVALUATING MODEL PERFORMANCE\n",
            "============================================================\n",
            "Ultralytics 8.3.188 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.6±0.4 ms, read: 1.4±0.8 MB/s, size: 2.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Detection/ColabRun_1/dataset/labels/val.cache... 31 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 31/31 40645.0it/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.8it/s 1.1s\n",
            "                   all         31         31      0.998          1      0.995      0.995\n",
            "Speed: 5.1ms preprocess, 14.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Detection/ColabRun_1/runs/detect/plane_detection\u001b[0m\n",
            "📊 Model Performance Metrics:\n",
            "   mAP@0.5:     0.995 (99.5%)\n",
            "   mAP@0.5:0.95: 0.995 (99.5%)\n",
            "   Precision:   0.998 (99.8%)\n",
            "   Recall:      1.000 (100.0%)\n",
            "\n",
            "🎉 Excellent performance! (mAP@0.5 > 90%)\n",
            "\n",
            "💾 Model saved to: /content/drive/MyDrive/Detection/ColabRun_1/yolo11_plane_detection_model_optimized.pt\n",
            "✅ Training pipeline completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Block 8: Geospatial Detection Functions\n",
        "Purpose: Functions to detect planes in satellite images and extract spatial coordinates\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def extract_geospatial_info(image_path):\n",
        "    \"\"\"\n",
        "    Extract geospatial information from satellite image (.tif)\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the satellite image\n",
        "\n",
        "    Returns:\n",
        "        dict: Geospatial information including CRS, transform, bounds\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with rasterio.open(image_path) as src:\n",
        "            return {\n",
        "                'has_geospatial': True,\n",
        "                'crs': src.crs,                    # Coordinate Reference System\n",
        "                'transform': src.transform,         # Pixel to world coordinate transformation\n",
        "                'bounds': src.bounds,              # Geographic bounds (left, bottom, right, top)\n",
        "                'width': src.width,                # Image width in pixels\n",
        "                'height': src.height,              # Image height in pixels\n",
        "                'pixel_size_x': src.transform[0],  # Pixel size in X direction (meters/degrees)\n",
        "                'pixel_size_y': abs(src.transform[4]),  # Pixel size in Y direction (meters/degrees)\n",
        "                'units': 'meters' if src.crs and 'utm' in str(src.crs).lower() else 'degrees'\n",
        "            }\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Could not extract geospatial info: {e}\")\n",
        "        return {'has_geospatial': False, 'error': str(e)}\n",
        "\n",
        "def pixel_to_world_coordinates(pixel_x, pixel_y, geospatial_info):\n",
        "    \"\"\"\n",
        "    Convert pixel coordinates to world coordinates (latitude/longitude or UTM)\n",
        "\n",
        "    Args:\n",
        "        pixel_x (int): X coordinate in pixels\n",
        "        pixel_y (int): Y coordinate in pixels\n",
        "        geospatial_info (dict): Geospatial information from extract_geospatial_info\n",
        "\n",
        "    Returns:\n",
        "        tuple: (world_x, world_y) or (None, None) if conversion fails\n",
        "    \"\"\"\n",
        "    if not geospatial_info['has_geospatial']:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        # Use rasterio transform to convert pixel to world coordinates\n",
        "        transform = geospatial_info['transform']\n",
        "        world_x, world_y = xy(transform, pixel_y, pixel_x)  # Note: y, x order for rasterio\n",
        "        return float(world_x), float(world_y)\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting coordinates: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def detect_planes_with_coordinates(model_path, original_tif_path, converted_jpg_path, confidence_threshold=0.25, output_dir=f'{COLAB_RUN}/results'):\n",
        "    \"\"\"\n",
        "    Detect planes in satellite image and return results with spatial coordinates\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to trained YOLO model\n",
        "        original_tif_path (str): Path to the original satellite image (.tif) for geospatial info\n",
        "        converted_jpg_path (str): Path to the converted .jpg image for detection\n",
        "        confidence_threshold (float): Minimum confidence for detections\n",
        "        output_dir (str): Directory to save results\n",
        "\n",
        "    Returns:\n",
        "        dict: Detection results with spatial coordinates\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"PLANE DETECTION WITH SPATIAL COORDINATES\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"📷 Original satellite image (.tif): {original_tif_path}\")\n",
        "    print(f\"🖼️ Converted image (.jpg): {converted_jpg_path}\")\n",
        "    print(f\"🤖 Model: {model_path}\")\n",
        "    print(f\"🎯 Confidence threshold: {confidence_threshold}\")\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Extract geospatial information from the original TIF\n",
        "    print(\"\\n📍 Extracting geospatial information from TIF...\")\n",
        "    geospatial_info = extract_geospatial_info(original_tif_path)\n",
        "\n",
        "    if geospatial_info['has_geospatial']:\n",
        "        print(\"✅ Geospatial information found:\")\n",
        "        print(f\"   CRS: {geospatial_info['crs']}\")\n",
        "        # Use original TIF dimensions for coordinate conversion\n",
        "        print(f\"   Original TIF size: {geospatial_info['width']} x {geospatial_info['height']} pixels\")\n",
        "        print(f\"   Pixel size: {geospatial_info['pixel_size_x']:.2f} x {geospatial_info['pixel_size_y']:.2f} {geospatial_info['units']}\")\n",
        "        if geospatial_info['bounds']:\n",
        "            bounds = geospatial_info['bounds']\n",
        "            print(f\"   Bounds: ({bounds.left:.6f}, {bounds.bottom:.6f}) to ({bounds.right:.6f}, {bounds.top:.6f})\")\n",
        "    else:\n",
        "        print(\"⚠️  No geospatial information found in TIF - only pixel coordinates will be available\")\n",
        "        # Attempt to get image dimensions from JPG for pixel coordinates if TIF fails\n",
        "        try:\n",
        "             img_jpg = cv2.imread(converted_jpg_path)\n",
        "             if img_jpg is not None:\n",
        "                 geospatial_info['width'] = img_jpg.shape[1]\n",
        "                 geospatial_info['height'] = img_jpg.shape[0]\n",
        "                 print(f\"   Using JPG dimensions for pixel coordinates: {geospatial_info['width']} x {geospatial_info['height']} pixels\")\n",
        "             else:\n",
        "                 print(f\"❌ Could not read JPG image to get dimensions: {converted_jpg_path}\")\n",
        "                 return None # Cannot proceed without dimensions\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error reading JPG image for dimensions: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "    # Load the trained model\n",
        "    print(f\"\\n🤖 Loading model...\")\n",
        "    try:\n",
        "        model = YOLO(model_path)\n",
        "        print(\"✅ Model loaded successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load model: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Run inference on the converted JPG image\n",
        "    print(f\"\\n🔍 Running plane detection on JPG image...\")\n",
        "    try:\n",
        "        # Run inference on the converted JPG image\n",
        "        results = model(converted_jpg_path, conf=confidence_threshold, save=False)\n",
        "        print(\"✅ Detection completed\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Detection failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Process detection results\n",
        "    detection_results = []\n",
        "\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "\n",
        "        if boxes is not None and len(boxes) > 0:\n",
        "            print(f\"\\n🎯 Found {len(boxes)} plane detection(s)!\")\n",
        "\n",
        "            # Get the dimensions of the image used for detection (the JPG)\n",
        "            # This is needed to correctly interpret the YOLO output (normalized coordinates)\n",
        "            detection_img_height, detection_img_width = result.orig_shape # Use orig_shape from YOLO result\n",
        "\n",
        "            for i, box in enumerate(boxes):\n",
        "                # Extract detection information from JPG coordinates\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()  # Bounding box coordinates in JPG pixels\n",
        "                confidence = float(box.conf.cpu().numpy()[0])  # Confidence score\n",
        "                class_id = int(box.cls.cpu().numpy()[0])       # Class ID\n",
        "                class_name = model.names[class_id]             # Class name\n",
        "\n",
        "                # Calculate center point in JPG pixel coordinates\n",
        "                center_x_jpg = int((x1 + x2) / 2)\n",
        "                center_y_jpg = int((y1 + y2) / 2)\n",
        "\n",
        "                # --- Coordinate Conversion ---\n",
        "                # Need to map JPG pixel coordinates back to original TIF pixel coordinates\n",
        "                # This requires knowing the relationship (scaling and offset) between the TIF and JPG.\n",
        "                # Since the conversion function `convert_tif_to_jpg` resizes while maintaining aspect ratio\n",
        "                # and doesn't crop, we can calculate the scaling factor.\n",
        "                # If the JPG was resized, the scaling factor is:\n",
        "                # scale_x = detection_img_width / original_tif_width\n",
        "                # scale_y = detection_img_height / original_tif_height\n",
        "                # However, the `convert_tif_to_jpg` function scales based on the largest dimension to a target size.\n",
        "                # A more robust approach is to use the original TIF dimensions extracted earlier and assume the JPG covers the same area,\n",
        "                # or ideally, calculate the scaling used during conversion precisely.\n",
        "                # For now, let's assume a simple scaling based on the ratio of dimensions if resizing occurred.\n",
        "\n",
        "                original_tif_width = geospatial_info.get('width')\n",
        "                original_tif_height = geospatial_info.get('height')\n",
        "\n",
        "                if original_tif_width is not None and original_tif_height is not None:\n",
        "                    # Calculate scaling factor applied during conversion\n",
        "                    scale_x = original_tif_width / detection_img_width\n",
        "                    scale_y = original_tif_height / detection_img_height\n",
        "\n",
        "                    # Convert JPG pixel coordinates to original TIF pixel coordinates\n",
        "                    center_x_tif = int(center_x_jpg * scale_x)\n",
        "                    center_y_tif = int(center_y_jpg * scale_y)\n",
        "\n",
        "                    # Convert TIF pixel coordinates to world coordinates\n",
        "                    world_x, world_y = pixel_to_world_coordinates(\n",
        "                        center_x_tif, center_y_tif, geospatial_info\n",
        "                    )\n",
        "                else:\n",
        "                     # Fallback: If TIF dimensions aren't available, just use JPG pixel coordinates\n",
        "                     print(\"⚠️ Original TIF dimensions not available for precise coordinate mapping.\")\n",
        "                     center_x_tif = center_x_jpg\n",
        "                     center_y_tif = center_y_jpg\n",
        "                     world_x, world_y = None, None # Cannot calculate world coordinates without TIF info\n",
        "\n",
        "\n",
        "                # Create detection record\n",
        "                detection = {\n",
        "                    'detection_id': i + 1,\n",
        "                    'class_name': class_name,\n",
        "                    'confidence': round(confidence, 3),\n",
        "                    'pixel_coordinates_jpg': { # Store JPG pixel coords\n",
        "                        'center_x': center_x_jpg,\n",
        "                        'center_y': center_y_jpg,\n",
        "                        'bbox': {\n",
        "                            'x1': int(x1), 'y1': int(y1),\n",
        "                            'x2': int(x2), 'y2': int(y2)\n",
        "                        }\n",
        "                    },\n",
        "                    'pixel_coordinates_tif': { # Store estimated TIF pixel coords\n",
        "                        'center_x': center_x_tif,\n",
        "                        'center_y': center_y_tif,\n",
        "                         # Bbox in TIF pixels is less reliable without knowing the exact padding/resizing logic\n",
        "                         # but we can estimate based on scaling\n",
        "                        'bbox': {\n",
        "                             'x1': int(x1 * scale_x) if original_tif_width is not None else None,\n",
        "                             'y1': int(y1 * scale_y) if original_tif_height is not None else None,\n",
        "                             'x2': int(x2 * scale_x) if original_tif_width is not None else None,\n",
        "                             'y2': int(y2 * scale_y) if original_tif_height is not None else None\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                # Add world coordinates if available\n",
        "                if world_x is not None and world_y is not None:\n",
        "                    if geospatial_info.get('units') == 'degrees':\n",
        "                        detection['geographic_coordinates'] = {\n",
        "                            'latitude': round(world_y, 8),\n",
        "                            'longitude': round(world_x, 8),\n",
        "                            'crs': str(geospatial_info['crs'])\n",
        "                        }\n",
        "                        coord_str = f\"({world_y:.6f}°N, {world_x:.6f}°E)\"\n",
        "                    else:\n",
        "                        detection['projected_coordinates'] = {\n",
        "                            'x': round(world_x, 2),\n",
        "                            'y': round(world_y, 2),\n",
        "                            'crs': str(geospatial_info['crs']),\n",
        "                            'units': geospatial_info['units']\n",
        "                        }\n",
        "                        coord_str = f\"({world_x:.1f}, {world_y:.1f}) {geospatial_info['units']}\"\n",
        "                else:\n",
        "                    coord_str = \"No spatial coordinates (TIF info missing)\"\n",
        "\n",
        "                detection_results.append(detection)\n",
        "\n",
        "                # Print detection details\n",
        "                print(f\"\\n   Detection #{i + 1}:\")\n",
        "                print(f\"   Class: {class_name}\")\n",
        "                print(f\"   Confidence: {confidence:.1%}\")\n",
        "                print(f\"   Pixel center (JPG): ({center_x_jpg}, {center_y_jpg})\")\n",
        "                if original_tif_width is not None:\n",
        "                    print(f\"   Pixel center (TIF est.): ({center_x_tif}, {center_y_tif})\")\n",
        "                print(f\"   World coordinates: {coord_str}\")\n",
        "        else:\n",
        "            print(\"\\n❌ No planes detected in the image\")\n",
        "\n",
        "    # Save results\n",
        "    if detection_results:\n",
        "        # Prepare results summary\n",
        "        results_summary = {\n",
        "            'input_image_tif': original_tif_path,\n",
        "            'input_image_jpg': converted_jpg_path,\n",
        "            'model_used': model_path,\n",
        "            'detection_settings': {\n",
        "                'confidence_threshold': confidence_threshold,\n",
        "                'model_version': 'YOLOv11'\n",
        "            },\n",
        "            'geospatial_info': geospatial_info,\n",
        "            'detections': detection_results,\n",
        "            'summary': {\n",
        "                'total_detections': len(detection_results),\n",
        "                'has_spatial_coordinates': geospatial_info['has_geospatial']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Save JSON results\n",
        "        json_path = os.path.join(output_dir, 'detection_results.json')\n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(results_summary, f, indent=2, default=str)\n",
        "        print(f\"\\n💾 Results saved to: {json_path}\")\n",
        "\n",
        "        # Create and save CSV\n",
        "        csv_data = []\n",
        "        for detection in detection_results:\n",
        "            row = {\n",
        "                'detection_id': detection['detection_id'],\n",
        "                'class_name': detection['class_name'],\n",
        "                'confidence': detection['confidence'],\n",
        "                'pixel_center_x_jpg': detection['pixel_coordinates_jpg']['center_x'],\n",
        "                'pixel_center_y_jpg': detection['pixel_coordinates_jpg']['center_y'],\n",
        "                 'pixel_center_x_tif_est': detection['pixel_coordinates_tif']['center_x'],\n",
        "                 'pixel_center_y_tif_est': detection['pixel_coordinates_tif']['center_y']\n",
        "            }\n",
        "\n",
        "            if 'geographic_coordinates' in detection:\n",
        "                row['latitude'] = detection['geographic_coordinates']['latitude']\n",
        "                row['longitude'] = detection['geographic_coordinates']['longitude']\n",
        "                row['crs'] = detection['geographic_coordinates']['crs']\n",
        "            elif 'projected_coordinates' in detection:\n",
        "                row['world_x'] = detection['projected_coordinates']['x']\n",
        "                row['world_y'] = detection['projected_coordinates']['y']\n",
        "                row['crs'] = detection['projected_coordinates']['crs']\n",
        "                row['units'] = detection['projected_coordinates']['units']\n",
        "\n",
        "            csv_data.append(row)\n",
        "\n",
        "        # Save CSV\n",
        "        if csv_data:\n",
        "            df = pd.DataFrame(csv_data)\n",
        "            csv_path = os.path.join(output_dir, 'detection_results.csv')\n",
        "            df.to_csv(csv_path, index=False)\n",
        "            print(f\"💾 CSV results saved to: {csv_path}\")\n",
        "\n",
        "        return results_summary\n",
        "\n",
        "    else:\n",
        "        print(\"\\n❌ No detections to save\")\n",
        "        return None\n",
        "\n",
        "print(\"✅ Geospatial detection functions loaded!\")\n",
        "print(f\"   Detection results will be saved in: f'{COLAB_RUN}/results'\")\n",
        "print(\"   Use detect_planes_with_coordinates() to detect planes with spatial coordinates\")"
      ],
      "metadata": {
        "id": "0_uo84_k2_7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44712a78-c73c-4911-f0d7-c9d533f38d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Geospatial detection functions loaded!\n",
            "   Detection results will be saved in: f'/content/drive/MyDrive/Detection/ColabRun_1/results'\n",
            "   Use detect_planes_with_coordinates() to detect planes with spatial coordinates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Block 9: Plane Extraction Function\n",
        "Purpose: Extract individual plane images from satellite image based on detection results\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def extract_plane_images(satellite_image_path, detection_results, output_dir=f'{COLAB_RUN}/results/extracted_planes', padding_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Extract individual plane images from satellite image based on detection results\n",
        "\n",
        "    Args:\n",
        "        satellite_image_path (str): Path to original satellite image\n",
        "        detection_results (dict): Results from detect_planes_with_coordinates\n",
        "        output_dir (str): Directory to save extracted plane images\n",
        "        padding_ratio (float): Additional padding around detected planes (0.2 = 20% padding)\n",
        "\n",
        "    Returns:\n",
        "        list: List of extracted plane image paths\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXTRACTING INDIVIDUAL PLANE IMAGES\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if not detection_results or not detection_results.get('detections'):\n",
        "        print(\"❌ No detections available for extraction\")\n",
        "        return []\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Read the original satellite image\n",
        "    print(f\"📷 Loading satellite image: {satellite_image_path}\")\n",
        "    try:\n",
        "        # Read with rasterio to preserve geospatial information\n",
        "        with rasterio.open(satellite_image_path) as src:\n",
        "            # Read image data\n",
        "            image_data = src.read()  # Shape: (bands, height, width)\n",
        "            profile = src.profile    # Geospatial metadata\n",
        "            transform = src.transform\n",
        "\n",
        "        # Convert to OpenCV format (height, width, bands)\n",
        "        if len(image_data.shape) == 3:\n",
        "            # Multi-band image\n",
        "            opencv_image = np.transpose(image_data, (1, 2, 0))\n",
        "        else:\n",
        "            # Single band image\n",
        "            opencv_image = image_data[0]\n",
        "\n",
        "        print(f\"✅ Image loaded: {opencv_image.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load satellite image: {e}\")\n",
        "        return []\n",
        "\n",
        "    extracted_paths = []\n",
        "    geospatial_info = detection_results.get('geospatial_info', {})\n",
        "\n",
        "    print(f\"\\n🎯 Extracting {len(detection_results['detections'])} detected planes...\")\n",
        "\n",
        "    for i, detection in enumerate(detection_results['detections']):\n",
        "        detection_id = detection['detection_id']\n",
        "        confidence = detection['confidence']\n",
        "\n",
        "        # Get bounding box coordinates - prioritize TIF coordinates if available\n",
        "        if 'pixel_coordinates_tif' in detection and detection['pixel_coordinates_tif'].get('bbox') and None not in detection['pixel_coordinates_tif']['bbox'].values():\n",
        "             bbox = detection['pixel_coordinates_tif']['bbox']\n",
        "             center_x = detection['pixel_coordinates_tif']['center_x']\n",
        "             center_y = detection['pixel_coordinates_tif']['center_y']\n",
        "             print(f\"   Using TIF estimated pixel coordinates for detection #{detection_id}\")\n",
        "        elif 'pixel_coordinates_jpg' in detection:\n",
        "             bbox = detection['pixel_coordinates_jpg']['bbox']\n",
        "             center_x = detection['pixel_coordinates_jpg']['center_x']\n",
        "             center_y = detection['pixel_coordinates_jpg']['center_y']\n",
        "             print(f\"   Using JPG pixel coordinates for detection #{detection_id}\")\n",
        "        else:\n",
        "             print(f\"⚠️  Skipping extraction for detection #{detection_id} due to missing pixel coordinates.\")\n",
        "             continue\n",
        "\n",
        "\n",
        "        x1, y1 = bbox['x1'], bbox['y1']\n",
        "        x2, y2 = bbox['x2'], bbox['y2']\n",
        "\n",
        "        # Calculate bounding box dimensions\n",
        "        bbox_width = x2 - x1\n",
        "        bbox_height = y2 - y1\n",
        "\n",
        "        # Add padding\n",
        "        padding_x = int(bbox_width * padding_ratio)\n",
        "        padding_y = int(bbox_height * padding_ratio)\n",
        "\n",
        "        # Calculate padded coordinates, ensuring they stay within image bounds\n",
        "        padded_x1 = max(0, x1 - padding_x)\n",
        "        padded_y1 = max(0, y1 - padding_y)\n",
        "        padded_x2 = min(opencv_image.shape[1], x2 + padding_x)\n",
        "        padded_y2 = min(opencv_image.shape[0], y2 + padding_y)\n",
        "\n",
        "        # Extract the plane region\n",
        "        if len(opencv_image.shape) == 3:\n",
        "            # Multi-band image\n",
        "            plane_image = opencv_image[padded_y1:padded_y2, padded_x1:padded_x2, :]\n",
        "        else:\n",
        "            # Single band image\n",
        "            plane_image = opencv_image[padded_y1:padded_y2, padded_x1:padded_x2]\n",
        "\n",
        "        # Generate filename with coordinates\n",
        "        if 'geographic_coordinates' in detection:\n",
        "            lat = detection['geographic_coordinates']['latitude']\n",
        "            lon = detection['geographic_coordinates']['longitude']\n",
        "            filename = f\"plane_{detection_id:03d}_lat{lat:.6f}_lon{lon:.6f}_conf{confidence:.2f}.tif\"\n",
        "        elif 'projected_coordinates' in detection:\n",
        "            x_coord = detection['projected_coordinates']['x']\n",
        "            y_coord = detection['projected_coordinates']['y']\n",
        "            filename = f\"plane_{detection_id:03d}_x{x_coord:.0f}_y{y_coord:.0f}_conf{confidence:.2f}.tif\"\n",
        "        else:\n",
        "            filename = f\"plane_{detection_id:03d}_px{center_x}_{center_y}_conf{confidence:.2f}.tif\"\n",
        "\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "\n",
        "        try:\n",
        "            # Calculate new geotransform for the extracted image\n",
        "            if geospatial_info.get('has_geospatial', False):\n",
        "                # Calculate the new geotransform for the cropped image\n",
        "                original_transform = geospatial_info['transform']\n",
        "\n",
        "                # Calculate world coordinates of the top-left corner of cropped image\n",
        "                crop_world_x, crop_world_y = xy(original_transform, padded_y1, padded_x1)\n",
        "\n",
        "                # Create new transform for cropped image\n",
        "                new_transform = rasterio.transform.Affine(\n",
        "                    original_transform.a,  # pixel width\n",
        "                    original_transform.b,  # row rotation\n",
        "                    crop_world_x,          # new top-left x coordinate\n",
        "                    original_transform.d,  # column rotation\n",
        "                    original_transform.e,  # pixel height (negative)\n",
        "                    crop_world_y           # new top-left y coordinate\n",
        "                )\n",
        "\n",
        "                # Update profile for the cropped image\n",
        "                new_profile = profile.copy()\n",
        "                new_profile.update({\n",
        "                    'height': plane_image.shape[0],\n",
        "                    'width': plane_image.shape[1],\n",
        "                    'transform': new_transform,\n",
        "                    'count': plane_image.shape[2] if len(plane_image.shape) == 3 else 1, # Update band count\n",
        "                    'dtype': str(plane_image.dtype) # Update data type\n",
        "                })\n",
        "\n",
        "                # Save as georeferenced TIFF\n",
        "                with rasterio.open(output_path, 'w', **new_profile) as dst:\n",
        "                    if len(plane_image.shape) == 3:\n",
        "                        # Multi-band image\n",
        "                        for band in range(plane_image.shape[2]):\n",
        "                            dst.write(plane_image[:, :, band], band + 1)\n",
        "                    else:\n",
        "                        # Single band image\n",
        "                        dst.write(plane_image, 1)\n",
        "\n",
        "            else:\n",
        "                # Save as regular TIFF without geospatial information\n",
        "                if len(plane_image.shape) == 3:\n",
        "                    # Convert to RGB for saving (if it's BGR from cv2.imread)\n",
        "                    if opencv_image.shape[2] == 3: # Check if it's a 3-channel image\n",
        "                        plane_image_rgb = cv2.cvtColor(plane_image, cv2.COLOR_BGR2RGB)\n",
        "                        Image.fromarray(plane_image_rgb).save(output_path)\n",
        "                    else: # Handle other multi-band images - save first 3 bands as RGB\n",
        "                        if plane_image.shape[2] >= 3:\n",
        "                             Image.fromarray(plane_image[:,:,:3]).save(output_path)\n",
        "                        else: # Handle images with less than 3 bands\n",
        "                             Image.fromarray(plane_image[:,:,0] if plane_image.shape[2] > 0 else plane_image).save(output_path)\n",
        "\n",
        "                else:\n",
        "                    # Grayscale image\n",
        "                    Image.fromarray(plane_image).save(output_path)\n",
        "\n",
        "            extracted_paths.append(output_path)\n",
        "\n",
        "            # Calculate spatial information for this plane\n",
        "            if 'geographic_coordinates' in detection:\n",
        "                coord_info = f\"Lat: {detection['geographic_coordinates']['latitude']:.6f}°, Lon: {detection['geographic_coordinates']['longitude']:.6f}°\"\n",
        "            elif 'projected_coordinates' in detection:\n",
        "                x_coord = detection['projected_coordinates']['x']\n",
        "                y_coord = detection['projected_coordinates']['y']\n",
        "                coord_info = f\"X: {x_coord:.1f}, Y: {y_coord:.1f} {detection['projected_coordinates'].get('units', '')}\"\n",
        "            else:\n",
        "                coord_info = f\"Pixel: ({center_x}, {center_y})\"\n",
        "\n",
        "            print(f\"   ✅ Plane {detection_id}: {plane_image.shape[1]}x{plane_image.shape[0]} pixels\")\n",
        "            print(f\"      Confidence: {confidence:.1%}\")\n",
        "            print(f\"      Coordinates: {coord_info}\")\n",
        "            print(f\"      Saved: {filename}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Failed to extract plane {detection_id}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"\\n✅ Extraction complete!\")\n",
        "    print(f\"   {len(extracted_paths)} plane images extracted\")\n",
        "    print(f\"   Saved to: {output_dir}\")\n",
        "\n",
        "    # Create summary file\n",
        "    summary = {\n",
        "        'source_image': satellite_image_path,\n",
        "        'extraction_settings': {\n",
        "            'padding_ratio': padding_ratio,\n",
        "            'total_detections': len(detection_results.get('detections', [])),\n",
        "            'successful_extractions': len(extracted_paths)\n",
        "        },\n",
        "        'extracted_planes': []\n",
        "    }\n",
        "\n",
        "    for i, path in enumerate(extracted_paths):\n",
        "         # Find the corresponding detection by filename\n",
        "         matching_detection = None\n",
        "         filename = os.path.basename(path)\n",
        "         for det in detection_results.get('detections', []):\n",
        "             det_filename_part = f\"plane_{det['detection_id']:03d}\"\n",
        "             if det_filename_part in filename:\n",
        "                 matching_detection = det\n",
        "                 break\n",
        "\n",
        "         if matching_detection:\n",
        "             plane_info = {\n",
        "                 'detection_id': matching_detection['detection_id'],\n",
        "                 'filename': filename,\n",
        "                 'confidence': matching_detection['confidence']\n",
        "                 # Pixel and spatial coordinates are already in the filename and can be inferred from detection_results\n",
        "             }\n",
        "\n",
        "             if 'geographic_coordinates' in matching_detection:\n",
        "                 plane_info['geographic_coordinates'] = matching_detection['geographic_coordinates']\n",
        "             elif 'projected_coordinates' in matching_detection:\n",
        "                 plane_info['projected_coordinates'] = matching_detection['projected_coordinates']\n",
        "             elif 'pixel_coordinates_tif' in matching_detection:\n",
        "                 plane_info['pixel_coordinates_tif'] = matching_detection['pixel_coordinates_tif']\n",
        "             elif 'pixel_coordinates_jpg' in matching_detection:\n",
        "                 plane_info['pixel_coordinates_jpg'] = matching_detection['pixel_coordinates_jpg']\n",
        "\n",
        "\n",
        "             summary['extracted_planes'].append(plane_info)\n",
        "         else:\n",
        "             print(f\"⚠️ Could not find matching detection for extracted file: {filename}\")\n",
        "             summary['extracted_planes'].append({'filename': filename, 'status': 'detection_not_found'})\n",
        "\n",
        "\n",
        "    # Save extraction summary\n",
        "    summary_path = os.path.join(output_dir, 'extraction_summary.json')\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump(summary, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"📋 Extraction summary saved: {summary_path}\")\n",
        "\n",
        "    return extracted_paths\n",
        "\n",
        "print(\"✅ Plane extraction function loaded!\")\n",
        "print(f\"   Extracted planes will be saved in: f'{COLAB_RUN}/results/extracted_planes'\")\n",
        "print(\"   Use extract_plane_images() to extract individual plane images with spatial coordinates\")"
      ],
      "metadata": {
        "id": "VzaVKO-z3CNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c5f7b9-f0cd-4994-932b-11c2b57decd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Plane extraction function loaded!\n",
            "   Extracted planes will be saved in: f'/content/drive/MyDrive/Detection/ColabRun_1/results/extracted_planes'\n",
            "   Use extract_plane_images() to extract individual plane images with spatial coordinates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Block 10: Complete Detection Pipeline\n",
        "Purpose: Complete pipeline for detecting planes and extracting them with spatial coordinates\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def complete_plane_detection_pipeline(model_path, satellite_image_path, output_base_dir=f'{COLAB_RUN}/results',\n",
        "                                    confidence_threshold=0.25, padding_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Complete pipeline for plane detection and extraction with spatial coordinates\n",
        "\n",
        "    Args:\n",
        "        model_path (str): Path to trained YOLO model\n",
        "        satellite_image_path (str): Path to satellite image (.tif)\n",
        "        output_base_dir (str): Base directory for saving results\n",
        "        confidence_threshold (float): Minimum confidence for detections\n",
        "        padding_ratio (float): Padding around extracted planes\n",
        "\n",
        "    Returns:\n",
        "        dict: Complete results including detection results and extracted plane paths\n",
        "    \"\"\"\n",
        "    print(\"🚀 \" + \"=\"*80)\n",
        "    print(\"COMPLETE PLANE DETECTION PIPELINE\")\n",
        "    print(\"=\"*80 + \" 🚀\")\n",
        "\n",
        "    # Create timestamped output directory\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir = os.path.join(output_base_dir, f\"plane_detection_{timestamp}\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"📁 Output directory: {output_dir}\")\n",
        "\n",
        "    # Step 0: Convert the input TIF image to JPG for detection\n",
        "    print(\"\\n🖼️ STEP 0: Converting input TIF to JPG...\")\n",
        "    converted_image_dir = os.path.join(output_dir, 'converted_input') # Save converted input in results dir\n",
        "    os.makedirs(converted_image_dir, exist_ok=True)\n",
        "    converted_files = convert_tif_to_jpg(\n",
        "        input_dir=os.path.dirname(satellite_image_path), # Use dirname to get directory\n",
        "        output_dir=converted_image_dir,\n",
        "        target_size=640 # Match training size\n",
        "    )\n",
        "\n",
        "    if not converted_files:\n",
        "         print(\"❌ Image conversion failed - pipeline stopped\")\n",
        "         return None\n",
        "\n",
        "    # Assuming only one image is processed at a time for the pipeline demo\n",
        "    converted_jpg_path = os.path.join(converted_image_dir, converted_files[0])\n",
        "    print(f\"✅ Input image converted to JPG: {converted_jpg_path}\")\n",
        "\n",
        "\n",
        "    # Step 1: Detect planes with spatial coordinates\n",
        "    print(f\"\\n🔍 STEP 1: Detecting planes...\")\n",
        "    detection_results = detect_planes_with_coordinates(\n",
        "        model_path=model_path,\n",
        "        original_tif_path=satellite_image_path, # Use original TIF for geospatial info\n",
        "        converted_jpg_path=converted_jpg_path, # Use converted JPG for detection\n",
        "        confidence_threshold=confidence_threshold,\n",
        "        output_dir=output_dir # Pass the timestamped output_dir\n",
        "    )\n",
        "\n",
        "    if not detection_results:\n",
        "        print(\"❌ Detection failed - pipeline stopped\")\n",
        "        return None\n",
        "\n",
        "    if 'detections' not in detection_results or not detection_results['detections']:\n",
        "        print(\"❌ No planes detected - pipeline stopped\")\n",
        "        return detection_results\n",
        "\n",
        "    # Step 2: Extract individual plane images\n",
        "    print(f\"\\n✂️ STEP 2: Extracting plane images...\")\n",
        "    extraction_dir = os.path.join(output_dir, 'extracted_planes') # Use timestamped output_dir\n",
        "    # Use the original TIF path for extraction as it contains the full resolution and geospatial data\n",
        "    extracted_paths = extract_plane_images(\n",
        "        satellite_image_path=satellite_image_path, # Use original TIF for extraction\n",
        "        detection_results=detection_results,\n",
        "        output_dir=extraction_dir,\n",
        "        padding_ratio=padding_ratio\n",
        "    )\n",
        "\n",
        "    # Step 3: Create visualization\n",
        "    print(f\"\\n📊 STEP 3: Creating visualization...\")\n",
        "    try:\n",
        "        visualization_path = create_detection_visualization(\n",
        "            satellite_image_path=satellite_image_path, # Use original TIF for visualization base\n",
        "            detection_results=detection_results,\n",
        "            output_path=os.path.join(output_dir, 'detection_visualization.jpg') # Use timestamped output_dir\n",
        "        )\n",
        "        print(f\"✅ Visualization saved: {visualization_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Visualization failed: {e}\")\n",
        "        visualization_path = None\n",
        "\n",
        "    # Step 4: Create final summary\n",
        "    final_results = {\n",
        "        'pipeline_info': {\n",
        "            'timestamp': timestamp,\n",
        "            'input_image_tif': satellite_image_path,\n",
        "            'input_image_jpg_used_for_detection': converted_jpg_path,\n",
        "            'model_used': model_path,\n",
        "            'output_directory': output_dir,\n",
        "            'settings': {\n",
        "                'confidence_threshold': confidence_threshold,\n",
        "                'padding_ratio': padding_ratio\n",
        "            }\n",
        "        },\n",
        "        'detection_results': detection_results,\n",
        "        'extracted_planes': {\n",
        "            'extraction_directory': extraction_dir,\n",
        "            'extracted_paths': extracted_paths,\n",
        "            'count': len(extracted_paths)\n",
        "        },\n",
        "        'visualization': {\n",
        "            'path': visualization_path\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Save final summary\n",
        "    summary_path = os.path.join(output_dir, 'pipeline_summary.json')\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump(final_results, f, indent=2, default=str)\n",
        "\n",
        "    # Print final summary\n",
        "    print(f\"\\n🎉 \" + \"=\"*80)\n",
        "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*80 + \" 🎉\")\n",
        "    print(f\"📷 Input image: {os.path.basename(satellite_image_path)}\")\n",
        "    print(f\"🎯 Planes detected: {len(detection_results.get('detections', []))}\") # Handle case with no detections\n",
        "    print(f\"✂️ Planes extracted: {len(extracted_paths)}\")\n",
        "    print(f\"📁 Results saved in: {output_dir}\")\n",
        "    print(f\"📋 Complete summary: {summary_path}\")\n",
        "\n",
        "    if detection_results.get('geospatial_info', {}).get('has_geospatial', False):\n",
        "        print(f\"🌍 Spatial coordinates: Available\")\n",
        "        print(f\"📍 Coordinate system: {detection_results['geospatial_info']['crs']}\")\n",
        "    else:\n",
        "        print(f\"🌍 Spatial coordinates: Not available (image has no geospatial information)\")\n",
        "\n",
        "    return final_results\n",
        "\n",
        "def create_detection_visualization(satellite_image_path, detection_results, output_path):\n",
        "    \"\"\"\n",
        "    Create a visualization showing detected planes on the satellite image\n",
        "\n",
        "    Args:\n",
        "        satellite_image_path (str): Path to original satellite image (.tif) for visualization base\n",
        "        detection_results (dict): Detection results\n",
        "        output_path (str): Path to save visualization\n",
        "\n",
        "    Returns:\n",
        "        str: Path to saved visualization\n",
        "    \"\"\"\n",
        "    # Read the original TIF image for visualization base\n",
        "    try:\n",
        "        with rasterio.open(satellite_image_path) as src:\n",
        "            # Read image data (assuming RGB or first 3 bands)\n",
        "            if src.count >= 3:\n",
        "                # Read first 3 bands (R, G, B)\n",
        "                img_data = src.read([src.indexes[0], src.indexes[1], src.indexes[2]]) # Read first 3 bands\n",
        "                # Transpose to HxWxB and convert to uint8\n",
        "                img = np.transpose(img_data, (1, 2, 0)).astype(np.uint8)\n",
        "                 # Attempt to convert to BGR if needed for cv2 drawing\n",
        "                if src.photometric == 'RGB':\n",
        "                     img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "            elif src.count == 1:\n",
        "                # Read single band (grayscale)\n",
        "                img = src.read(1).astype(np.uint8)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) # Convert to BGR for drawing\n",
        "            else:\n",
        "                 raise Exception(f\"Unsupported number of bands in TIF: {src.count}\")\n",
        "\n",
        "    except Exception as e:\n",
        "         print(f\"❌ Failed to read TIF image for visualization: {e}\")\n",
        "         # Fallback to reading the converted JPG if TIF fails\n",
        "         if 'pipeline_info' in detection_results and 'input_image_jpg_used_for_detection' in detection_results['pipeline_info']:\n",
        "             converted_jpg_path = detection_results['pipeline_info']['input_image_jpg_used_for_detection']\n",
        "             print(f\"⚠️  Attempting to use converted JPG for visualization: {converted_jpg_path}\")\n",
        "             img = cv2.imread(converted_jpg_path)\n",
        "             if img is None:\n",
        "                 raise Exception(f\"Could not read converted JPG for visualization: {converted_jpg_path}\")\n",
        "             else:\n",
        "                 # Adjust detection coordinates if using JPG for visualization\n",
        "                 print(\"⚠️  Using JPG for visualization, detection coordinates might not align perfectly with original TIF.\")\n",
        "                 # We'll use the JPG pixel coordinates from the detection results\n",
        "                 use_jpg_coords = True\n",
        "         else:\n",
        "            raise Exception(f\"Could not read satellite image for visualization: {e}\")\n",
        "\n",
        "    if img is None:\n",
        "         raise Exception(\"Could not read any image for visualization\")\n",
        "\n",
        "    # Create a copy for annotation\n",
        "    annotated_img = img.copy()\n",
        "\n",
        "    # Determine which coordinates to use for drawing based on whether original TIF was loaded successfully\n",
        "    use_jpg_coords = False\n",
        "    if 'pipeline_info' in detection_results and 'input_image_jpg_used_for_detection' in detection_results['pipeline_info']:\n",
        "         # Check if the image currently loaded is the JPG (i.e., TIF read failed)\n",
        "         if img.shape[:2] == cv2.imread(detection_results['pipeline_info']['input_image_jpg_used_for_detection']).shape[:2]:\n",
        "             use_jpg_coords = True\n",
        "\n",
        "\n",
        "    # Draw detections\n",
        "    if 'detections' in detection_results:\n",
        "        for detection in detection_results['detections']:\n",
        "            # Get bounding box coordinates\n",
        "            if use_jpg_coords:\n",
        "                bbox = detection['pixel_coordinates_jpg']['bbox']\n",
        "                center_x = detection['pixel_coordinates_jpg']['center_x']\n",
        "                center_y = detection['pixel_coordinates_jpg']['center_y']\n",
        "            else:\n",
        "                 # Use estimated TIF coordinates if TIF was read successfully\n",
        "                 bbox = detection['pixel_coordinates_tif']['bbox']\n",
        "                 center_x = detection['pixel_coordinates_tif']['center_x']\n",
        "                 center_y = detection['pixel_coordinates_tif']['center_y']\n",
        "                 # Ensure bbox coordinates are not None if TIF dimensions were missing\n",
        "                 if None in bbox.values():\n",
        "                     print(f\"⚠️ Skipping drawing for detection {detection['detection_id']} due to missing TIF bbox coordinates.\")\n",
        "                     continue\n",
        "\n",
        "\n",
        "            confidence = detection['confidence']\n",
        "            detection_id = detection['detection_id']\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(annotated_img, (bbox['x1'], bbox['y1']), (bbox['x2'], bbox['y2']), (0, 255, 0), 3)\n",
        "\n",
        "            # Draw center point\n",
        "            cv2.circle(annotated_img, (center_x, center_y), 5, (0, 0, 255), -1)\n",
        "\n",
        "            # Add text label\n",
        "            label = f\"Plane {detection_id} ({confidence:.1%})\"\n",
        "            cv2.putText(annotated_img, label, (bbox['x1'], bbox['y1'] - 10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "            # Add coordinate information if available\n",
        "            coord_text = \"Coords N/A\"\n",
        "            if 'geographic_coordinates' in detection:\n",
        "                lat = detection['geographic_coordinates']['latitude']\n",
        "                lon = detection['geographic_coordinates']['longitude']\n",
        "                coord_text = f\"({lat:.6f}, {lon:.6f})\"\n",
        "            elif 'projected_coordinates' in detection:\n",
        "                x_coord = detection['projected_coordinates']['x']\n",
        "                y_coord = detection['projected_coordinates']['y']\n",
        "                coord_text = f\"({x_coord:.0f}, {y_coord:.0f})\"\n",
        "            elif use_jpg_coords:\n",
        "                 coord_text = f\"Pixel (JPG): ({center_x}, {center_y})\"\n",
        "            else:\n",
        "                 coord_text = f\"Pixel (TIF est.): ({center_x}, {center_y})\"\n",
        "\n",
        "\n",
        "            cv2.putText(annotated_img, coord_text, (bbox['x1'], bbox['y2'] + 25),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "\n",
        "    # Save visualization\n",
        "    cv2.imwrite(output_path, annotated_img)\n",
        "    return output_path\n",
        "\n",
        "# Example usage function\n",
        "def demo_complete_pipeline(image_name):\n",
        "    \"\"\"\n",
        "    Demo function showing how to use the complete pipeline\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"DEMO: COMPLETE PLANE DETECTION PIPELINE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Check if model exists\n",
        "    model_path = f'{COLAB_RUN}/yolo11_plane_detection_model_optimized.pt'\n",
        "    if not os.path.exists(model_path):\n",
        "        print(\"❌ Trained model not found!\")\n",
        "        print(f\"   Expected location: {model_path}\")\n",
        "        print(\"   Please run the training blocks first\")\n",
        "        return\n",
        "\n",
        "    # Example satellite image path (replace with your actual image)\n",
        "    # Make sure this sample image is accessible, e.g., uploaded to Colab or Drive\n",
        "    satellite_image = f'{COLAB_RUN}/{image_name}'\n",
        "\n",
        "    print(f\"📋 Pipeline configuration:\")\n",
        "    print(f\"   Model: {model_path}\")\n",
        "    print(f\"   Satellite image: {satellite_image}\")\n",
        "    print(f\"   Confidence threshold: 0.25\")\n",
        "    print(f\"   Padding ratio: 0.2\")\n",
        "\n",
        "    if os.path.exists(satellite_image):\n",
        "        # Run complete pipeline\n",
        "        results = complete_plane_detection_pipeline(\n",
        "            model_path=model_path,\n",
        "            satellite_image_path=satellite_image,\n",
        "            confidence_threshold=0.25,\n",
        "            padding_ratio=0.2\n",
        "        )\n",
        "\n",
        "        if results:\n",
        "            print(\"\\n✅ Pipeline demo completed successfully!\")\n",
        "            return results\n",
        "        else:\n",
        "            print(\"\\n❌ Pipeline demo failed\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n⚠️  Sample satellite image not found: {satellite_image}\")"
      ],
      "metadata": {
        "id": "TgDXdyv43FMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_complete_pipeline('PSScene_20250829_070722_75_24f6_cloud_10.0.tif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpFVcC19kzJR",
        "outputId": "9b128a55-4cb7-4c61-d5d5-3d302bbb82ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DEMO: COMPLETE PLANE DETECTION PIPELINE\n",
            "================================================================================\n",
            "📋 Pipeline configuration:\n",
            "   Model: /content/drive/MyDrive/Detection/ColabRun_1/yolo11_plane_detection_model_optimized.pt\n",
            "   Satellite image: /content/drive/MyDrive/Detection/ColabRun_1/PSScene_20250829_070722_75_24f6_cloud_10.0.tif\n",
            "   Confidence threshold: 0.25\n",
            "   Padding ratio: 0.2\n",
            "🚀 ================================================================================\n",
            "COMPLETE PLANE DETECTION PIPELINE\n",
            "================================================================================ 🚀\n",
            "📁 Output directory: /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807\n",
            "\n",
            "🖼️ STEP 0: Converting input TIF to JPG...\n",
            "Found 1 .tif files to convert...\n",
            "Processing 1/1: PSScene_20250829_070722_75_24f6_cloud_10.0.tif\n",
            "   Original size: 10240x8192\n",
            "   Resized to: 640x512\n",
            "   ✅ Converted: PSScene_20250829_070722_75_24f6_cloud_10.0.tif -> PSScene_20250829_070722_75_24f6_cloud_10.0.jpg\n",
            "\n",
            "✅ Conversion complete! 1/1 files converted successfully.\n",
            "✅ Input image converted to JPG: /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/converted_input/PSScene_20250829_070722_75_24f6_cloud_10.0.jpg\n",
            "\n",
            "🔍 STEP 1: Detecting planes...\n",
            "================================================================================\n",
            "PLANE DETECTION WITH SPATIAL COORDINATES\n",
            "================================================================================\n",
            "📷 Original satellite image (.tif): /content/drive/MyDrive/Detection/ColabRun_1/PSScene_20250829_070722_75_24f6_cloud_10.0.tif\n",
            "🖼️ Converted image (.jpg): /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/converted_input/PSScene_20250829_070722_75_24f6_cloud_10.0.jpg\n",
            "🤖 Model: /content/drive/MyDrive/Detection/ColabRun_1/yolo11_plane_detection_model_optimized.pt\n",
            "🎯 Confidence threshold: 0.25\n",
            "\n",
            "📍 Extracting geospatial information from TIF...\n",
            "✅ Geospatial information found:\n",
            "   CRS: EPSG:4326\n",
            "   Original TIF size: 10240 x 8192 pixels\n",
            "   Pixel size: 0.00 x 0.00 degrees\n",
            "   Bounds: (59.806045, 23.069802) to (60.156481, 23.328699)\n",
            "\n",
            "🤖 Loading model...\n",
            "✅ Model loaded successfully\n",
            "\n",
            "🔍 Running plane detection on JPG image...\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/converted_input/PSScene_20250829_070722_75_24f6_cloud_10.0.jpg: 512x640 2 items, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "✅ Detection completed\n",
            "\n",
            "🎯 Found 2 plane detection(s)!\n",
            "\n",
            "   Detection #1:\n",
            "   Class: item\n",
            "   Confidence: 95.1%\n",
            "   Pixel center (JPG): (294, 220)\n",
            "   Pixel center (TIF est.): (4704, 3520)\n",
            "   World coordinates: (23.217439°N, 59.967044°E)\n",
            "\n",
            "   Detection #2:\n",
            "   Class: item\n",
            "   Confidence: 27.1%\n",
            "   Pixel center (JPG): (313, 457)\n",
            "   Pixel center (TIF est.): (5008, 7312)\n",
            "   World coordinates: (23.097598°N, 59.977448°E)\n",
            "\n",
            "💾 Results saved to: /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/detection_results.json\n",
            "💾 CSV results saved to: /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/detection_results.csv\n",
            "\n",
            "✂️ STEP 2: Extracting plane images...\n",
            "\n",
            "================================================================================\n",
            "EXTRACTING INDIVIDUAL PLANE IMAGES\n",
            "================================================================================\n",
            "📷 Loading satellite image: /content/drive/MyDrive/Detection/ColabRun_1/PSScene_20250829_070722_75_24f6_cloud_10.0.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rasterio._env:CPLE_NotSupported in 'YCbCr JPEG' is an unexpected value for COMPRESS creation option of type string-select.\n",
            "WARNING:rasterio._env:CPLE_IllegalArg in COMPRESS=YCbCr JPEG value not recognised, ignoring.\n",
            "WARNING:rasterio._env:CPLE_NotSupported in 'YCbCr JPEG' is an unexpected value for COMPRESS creation option of type string-select.\n",
            "WARNING:rasterio._env:CPLE_IllegalArg in COMPRESS=YCbCr JPEG value not recognised, ignoring.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Image loaded: (8192, 10240, 3)\n",
            "\n",
            "🎯 Extracting 2 detected planes...\n",
            "   Using TIF estimated pixel coordinates for detection #1\n",
            "   ❌ Failed to extract plane 1: plane_001_lat23.217439_lon59.967044_conf0.95.tif: Currently, PHOTOMETRIC=YCBCR requires COMPRESS=JPEG\n",
            "   Using TIF estimated pixel coordinates for detection #2\n",
            "   ❌ Failed to extract plane 2: plane_002_lat23.097598_lon59.977448_conf0.27.tif: Currently, PHOTOMETRIC=YCBCR requires COMPRESS=JPEG\n",
            "\n",
            "✅ Extraction complete!\n",
            "   0 plane images extracted\n",
            "   Saved to: /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/extracted_planes\n",
            "📋 Extraction summary saved: /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/extracted_planes/extraction_summary.json\n",
            "\n",
            "📊 STEP 3: Creating visualization...\n",
            "✅ Visualization saved: /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/detection_visualization.jpg\n",
            "\n",
            "🎉 ================================================================================\n",
            "PIPELINE COMPLETED SUCCESSFULLY!\n",
            "================================================================================ 🎉\n",
            "📷 Input image: PSScene_20250829_070722_75_24f6_cloud_10.0.tif\n",
            "🎯 Planes detected: 2\n",
            "✂️ Planes extracted: 0\n",
            "📁 Results saved in: /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807\n",
            "📋 Complete summary: /content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/pipeline_summary.json\n",
            "🌍 Spatial coordinates: Available\n",
            "📍 Coordinate system: EPSG:4326\n",
            "\n",
            "✅ Pipeline demo completed successfully!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pipeline_info': {'timestamp': '20250830_154807',\n",
              "  'input_image_tif': '/content/drive/MyDrive/Detection/ColabRun_1/PSScene_20250829_070722_75_24f6_cloud_10.0.tif',\n",
              "  'input_image_jpg_used_for_detection': '/content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/converted_input/PSScene_20250829_070722_75_24f6_cloud_10.0.jpg',\n",
              "  'model_used': '/content/drive/MyDrive/Detection/ColabRun_1/yolo11_plane_detection_model_optimized.pt',\n",
              "  'output_directory': '/content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807',\n",
              "  'settings': {'confidence_threshold': 0.25, 'padding_ratio': 0.2}},\n",
              " 'detection_results': {'input_image_tif': '/content/drive/MyDrive/Detection/ColabRun_1/PSScene_20250829_070722_75_24f6_cloud_10.0.tif',\n",
              "  'input_image_jpg': '/content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/converted_input/PSScene_20250829_070722_75_24f6_cloud_10.0.jpg',\n",
              "  'model_used': '/content/drive/MyDrive/Detection/ColabRun_1/yolo11_plane_detection_model_optimized.pt',\n",
              "  'detection_settings': {'confidence_threshold': 0.25,\n",
              "   'model_version': 'YOLOv11'},\n",
              "  'geospatial_info': {'has_geospatial': True,\n",
              "   'crs': CRS.from_wkt('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]'),\n",
              "   'transform': Affine(3.4222257774090686e-05, 0.0, 59.806045486189475,\n",
              "          0.0, -3.160362068537056e-05, 23.328699209260403),\n",
              "   'bounds': BoundingBox(left=59.806045486189475, bottom=23.069802348605847, right=60.156481405796164, top=23.328699209260403),\n",
              "   'width': 10240,\n",
              "   'height': 8192,\n",
              "   'pixel_size_x': 3.4222257774090686e-05,\n",
              "   'pixel_size_y': 3.160362068537056e-05,\n",
              "   'units': 'degrees'},\n",
              "  'detections': [{'detection_id': 1,\n",
              "    'class_name': 'item',\n",
              "    'confidence': 0.951,\n",
              "    'pixel_coordinates_jpg': {'center_x': 294,\n",
              "     'center_y': 220,\n",
              "     'bbox': {'x1': 59, 'y1': 70, 'x2': 529, 'y2': 369}},\n",
              "    'pixel_coordinates_tif': {'center_x': 4704,\n",
              "     'center_y': 3520,\n",
              "     'bbox': {'x1': 955, 'y1': 1133, 'x2': 8476, 'y2': 5910}},\n",
              "    'geographic_coordinates': {'latitude': 23.21743866,\n",
              "     'longitude': 59.9670441,\n",
              "     'crs': 'EPSG:4326'}},\n",
              "   {'detection_id': 2,\n",
              "    'class_name': 'item',\n",
              "    'confidence': 0.271,\n",
              "    'pixel_coordinates_jpg': {'center_x': 313,\n",
              "     'center_y': 457,\n",
              "     'bbox': {'x1': 12, 'y1': 402, 'x2': 615, 'y2': 512}},\n",
              "    'pixel_coordinates_tif': {'center_x': 5008,\n",
              "     'center_y': 7312,\n",
              "     'bbox': {'x1': 192, 'y1': 6439, 'x2': 9855, 'y2': 8192}},\n",
              "    'geographic_coordinates': {'latitude': 23.09759773,\n",
              "     'longitude': 59.97744766,\n",
              "     'crs': 'EPSG:4326'}}],\n",
              "  'summary': {'total_detections': 2, 'has_spatial_coordinates': True}},\n",
              " 'extracted_planes': {'extraction_directory': '/content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/extracted_planes',\n",
              "  'extracted_paths': [],\n",
              "  'count': 0},\n",
              " 'visualization': {'path': '/content/drive/MyDrive/Detection/ColabRun_1/results/plane_detection_20250830_154807/detection_visualization.jpg'}}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}